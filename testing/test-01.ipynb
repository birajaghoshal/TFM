{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# jupyter notebook - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/32565829/simple-way-to-measure-cell-execution-time-in-ipython-notebook\n",
    "#%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "#%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python check\n",
    "print (\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow check\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution time check\n",
    "%time\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python embebed seems not to work?\n",
    "text = \"this is a test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python print(text)``` of python inline feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-do // clean // delete // check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|Categoría|Imagen|\n",
    "|-|-|\n",
    "| Epitelio canceroso | ![](../img-raw/01_TUMOR/) |\n",
    "| Estroma simple |  |\n",
    "| Estroma complejo |  |\n",
    "| Células inmunes |  |\n",
    "| Material variado |  |\n",
    "| Glándulas mucosas normales |  |\n",
    "| Tejido adiposo |  |\n",
    "| Imagen de fondo |  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Muestra check it out\n",
    "\n",
    "Cosas a tener en cuenta.\n",
    "\n",
    "   0. Son categorías con el mismo número de elementos\n",
    "   1. seleccionarlas yo mismo de forma aleatoria (¿?)\n",
    "   2. aleatorizar las categorías \n",
    "   3. seleccionarlas mediante la clase StratifiedShuffleSplit de Scikit-Learn\n",
    "   4. guardar la seleccion en variables(array) / archivo, o un diccionario con clave(tipo de imagen = test / training / cross validation) nombre  para poder leer desde otro jupyter notebook¿?\n",
    "   \n",
    "debo hacer un diccionario descripcion // contenido // label? pag 80\n",
    "   \n",
    "deberia hacer el mismo tipo de muestra multicategoria / binaria que hacen en el estudio principal? en el primero incluir todas las categorias en el segundo solo tumor/estroma, asi se comparan los resultados con el estudio principal y con los estudios que usan tecnicas tradicionales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests check it out\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "\n",
    "# in order to be reproducible\n",
    "rnd.seed(16180)\n",
    "def mySeed(seed=16180):\n",
    "    #tf.reset_default_graph()\n",
    "    #tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# dataset folder's name img-raw/ --> there are 8 subfolders\n",
    "dataset = \"img-raw/\"\n",
    "\n",
    "#page-book-80\n",
    "\n",
    "#utility to plot img\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image.astype(np.uint8),interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "#RGB img with 150x150px\n",
    "width = 150\n",
    "height = 150\n",
    "channels = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the net with img\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# change it in production\n",
    "PATH_TO_IMG = \"../img-raw\"\n",
    "\n",
    "# os commands\n",
    "#os.getcwd() #pwd\n",
    "imgFolder =os.listdir(PATH_TO_IMG) #folder list of a PATH\n",
    "imgFolder.sort() #sort the list, just in case Tumor and stroma logistic regression\n",
    "\n",
    "for cat in imgFolder:\n",
    "    #print(cat)\n",
    "    aux = os.path.join(PATH_TO_IMG, cat) #concatenate img folder + category subfolder\n",
    "    #print (aux)\n",
    "    #aux2 = os.listdir(os.path.join(PATH_TO_IMG, cat)) #list of all img of a folder without aux var\n",
    "    #print(type(aux2))\n",
    "    #print(os.listdir(aux)) #list of all img of a folder\n",
    "\n",
    "#csv vs list¿?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# PATH_TO_IMG = \"../img-raw\"\n",
    "# list_images = [PATH_TO_IMG+f for f in os.listdir(PATH_TO_IMG) if re.search('tif|TIF', f)]\n",
    "\n",
    "# print(len(list_images))\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../img-raw\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture relative paths for dataset folder change it accordingly\n",
    "INCEPTION_V3_PATH = \"../architecture/pretrained-model/inception_v3.ckpt\"\n",
    "INCEPTION_V4_PATH = \"../architecture/pretrained-model/inception_v4.ckpt\"\n",
    "VGG16_PATH = \"../architecture/pretrained-model/vgg_16.ckpt\"\n",
    "VGG19_PATH = \"../architecture/pretrained-model/vgg_19.ckpt\"\n",
    "RESNET_V1_50 = \"../architecture/pretrained-model/resnet_v1_50.ckpt\"\n",
    "RESNET_V1_152 = \"../architecture/pretrained-model/resnet_v1_152.ckpt\"\n",
    "\n",
    "# can I rename train.graph and eval.graph\n",
    "RESNET_V2_50 = \"../architecture/pretrained-model/\"\n",
    "RESNET_V2_152 = \"../architecture/pretrained-model/\"\n",
    "\n",
    "# to check\n",
    "ALEXNET_PATH = \"\"\n",
    "LENET_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version --> add to test & system jupyter notebooks\n",
    "import numpy\n",
    "import scipy\n",
    "# check below imports\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "print(\"scipy=={}\".format(scipy.__version__))\n",
    "print(\"numpy=={}\".format(numpy.__version__))\n",
    "print(\"scikit-image=={}\".format(skimage.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Once you have this program with you, use the following approach to use the model:\n",
    "\n",
    "from inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\n",
    "\n",
    "height = 299\n",
    "width = 299\n",
    "channels = 3\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, height, width, channels])\n",
    "with slim.arg_scope(inception_resnet_v2_arg_scope()):\n",
    "     logits, end_points = inception_resnet_v2(X, num_classes=1001,is_training=False)\n",
    "With this you have all the network in memory, Now you can initialize the network with checkpoint file(ckpt) by using tf.train.saver:\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, \"/home/pramod/Downloads/inception_resnet_v2_2016_08_30.ckpt\")\n",
    "If you want to do bottle feature extraction, its simple like lets say you want to get features from last layer, then simply you have to declare predictions = end_points[\"Logits\"] If you want to get it for other intermediate layer, you can get those names from the above program inception_resnet_v2.py\n",
    "\n",
    "After that you can call: output =  sess.run(predictions, feed_dict={X:batch_images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the net via tfrecords\n",
    "# http://www.machinelearninguru.com/deep_learning/tensorflow/basics/tfrecord/tfrecord.html\n",
    "# https://github.com/KaimingHe/deep-residual-networks --> graficos interesantes\n",
    "# http://ethereon.github.io/netscope/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre procesado de imágenes para la arquitectura Alexnet (2012)\n",
    "\n",
    "* just to get the size to feed the net --> KISS for now\n",
    "* data augmentation in v0.2 with or without tensorflow\n",
    "    * rotation\n",
    "    * random crop\n",
    "    * [link](http://www.scipy-lectures.org/advanced/image_processing/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the images are tagged by the name folder\n",
    "\n",
    "# https://stackoverflow.com/questions/6508576/what-is-the-difference-between-sys-and-os-sys\n",
    "#import os\n",
    "import sys\n",
    "\n",
    "# relative path (change it)!\n",
    "PATH_TO_IMG = \"../img-raw\"\n",
    "\n",
    "# like handson (use mine instead)?!\n",
    "imgCategories = sorted([category for category in os.listdir(PATH_TO_IMG)\n",
    "                  if os.path.isdir(os.path.join(PATH_TO_IMG, category))])\n",
    "\n",
    "#print(imgCategories)\n",
    "#type(imgCategories)\n",
    "\n",
    "\"\"\"\n",
    "getting all img's names for each category\n",
    "https://docs.python.org/2/library/collections.html#collections.defaultdict\n",
    "\n",
    "TO-DO --> make a function instead\n",
    "\"\"\"\n",
    "from collections import defaultdict\n",
    "\n",
    "#https://docs.python.org/3.3/library/collections.html#collections.defaultdict\n",
    "imgPaths = defaultdict(list)\n",
    "#type(imgPaths)\n",
    "\n",
    "# what's the best solution? get a dict or make a file instead\n",
    "\n",
    "for imgCategory in imgCategories:\n",
    "    imgFolder = os.path.join(PATH_TO_IMG, imgCategory)\n",
    "    for img in os.listdir(imgFolder):\n",
    "        if img.endswith(\".tif\"): #just in case there are other kind of files\n",
    "            imgPaths[imgCategory].append(os.path.join(imgFolder, img).replace(\"\\\\\",\"/\"))\n",
    "\n",
    "# sort imgPaths --> necesary?\n",
    "# for imgPath in imgPaths.values():\n",
    "#     imgPath.sort()  \n",
    "# imgPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the net via python\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 299, 299, 3], name=\"X\")\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    logits, end_points = inception.inception_v3(\n",
    "        X, num_classes=1001, is_training=False)\n",
    "predictions = end_points[\"Predictions\"]\n",
    "saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of img in the folder\n",
    "import os, os.path\n",
    "\n",
    "PATH_TO_IMG = \"../img-raw/\"\n",
    "\n",
    "# simple version for working with CWD\n",
    "print (len([name for name in os.listdir(PATH_TO_IMG) if os.path.isfile(name)]))\n",
    "\n",
    "# path joining version for other paths\n",
    "# DIR = '/tmp'\n",
    "# print len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "# images_dir =\"../img-raw/01_TUMOR\"\n",
    "images_dir =\"../img-raw\"\n",
    "# list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('tif|TIF', f)]\n",
    "\n",
    "#len(list_images)\n",
    "#list_images\n",
    "\n",
    "# for counter, image in enumerate(list_images): # comienza en 0\n",
    "#     print(counter)\n",
    "#     print(image)\n",
    "#     print(re.split('_\\d+',image.split('/')[1])[0]) #img-raw\n",
    "#     print(re.split('_\\d+',image.split('/')[1])[0]) #img-raw\n",
    "#     print(re.split('_\\d+',image.split('/')[2])[0]) # nombre foto\n",
    "\n",
    "\n",
    "# myImage = '../img-raw/01_TUMOR/10009_CRC-Prim-HE-03_009.tif_Row_301_Col_151.tif'\n",
    "# print(re.split('_\\d+',myImage.split('/')[0])[0]) # parent ..\n",
    "# print(re.split('_\\d+',myImage.split('/')[1])[0]) #img-raw\n",
    "# print(re.split('_\\d+',myImage.split('/')[2])[0]) # nombre categoria\n",
    "# print(re.split('_\\d+',myImage.split('/')[3])[3]) # nombre foto\n",
    "\n",
    "#listado de las fotografias\n",
    "cos.listdir(images_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network_p11\n",
    "htatps://www.kaggle.com/craigglastonbury/using-inceptionv3-features-svm-classifier/code\n",
    "    \n",
    "decodejpg \n",
    "https://stackoverflow.com/questions/34484148/feeding-image-data-in-tensorflow-for-transfer-learning\n",
    "\n",
    "# This is a script I applied early in toe competition ~ LB = 3. With bounding box regression  \n",
    "# (applying this to fishes rather than whole images achieves a much better score)\n",
    "# I used this script to learn about CNNs, feature extraction and using features learned by the InceptionV3 CNN\n",
    "# to perform classificaiton using a SVM architecture.\n",
    "# Inspired (adapted heavily) from: http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import svm\n",
    "\n",
    "model_dir = 'latest_submission/'\n",
    "# all training images\n",
    "images_dir = 'SVM_training_set/'\n",
    "list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)]\n",
    "\n",
    "\n",
    "# setup tensorFlow graph initiation\n",
    "def create_graph():\n",
    "\twith gfile.FastGFile(os.path.join(model_dir, 'output.pb'), 'rb') as f:\n",
    "\t\tgraph_def = tf.GraphDef()\n",
    "\t\tgraph_def.ParseFromString(f.read())\n",
    "\t\t_ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "# extract all features from pool layer of InceptionV3\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tlabels = []\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\t\tlabels.append(re.split('_\\d+',image.split('/')[1])[0])\n",
    "\t\treturn features, labels\n",
    "\n",
    "\n",
    "features,labels = extract_features(list_images)\n",
    "\n",
    "pickle.dump(features, open('features', 'wb'))\n",
    "pickle.dump(labels, open('labels', 'wb'))\n",
    "\n",
    "features = pickle.load(open('features'))\n",
    "labels = pickle.load(open('labels'))\n",
    "\n",
    "# run a 10-fold CV SVM using probabilistic outputs. \n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=0)\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# probabalistic SVM\n",
    "clf =  sklearn.calibration.CalibratedClassifierCV(svm)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "k_fold = KFold(len(labels),n_folds=10, shuffle=False, random_state=0)\n",
    "C_array=[0.001,0.01,0.1,1,10]\n",
    "C_scores=[]\n",
    "\n",
    "for k in C_array:\n",
    "\tclf = svm.SVC(kernel='linear', C=k)\n",
    "\tscores= cross_val_score(clf, features, labels, cv=k_fold, n_jobs=-1)\n",
    "\tC_scores.append(scores.mean())\n",
    "\tprint C_scores\n",
    "\n",
    "#C = 0.1 is best\n",
    "\n",
    "#clf = svm.LinearSVC(C=0.1)\n",
    "clf = svm.SVC(kernel='linear', C=0.1,probability=True)\n",
    "\n",
    "# final_model = clf.fit(features, labels)\n",
    "\n",
    "final_model = CalibratedClassifierCV(clf,cv=10,method='sigmoid')\n",
    "final_model = clf.fit(features, labels)\n",
    "\n",
    "\n",
    "test_dir='latest_submission/test_stg1/test_stg1/'\n",
    "list_images = [test_dir+f for f in os.listdir(test_dir) if re.search('jpg|JPG', f)]\n",
    "\n",
    "\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\treturn features\n",
    "\n",
    "\n",
    "features_test = extract_features(list_images)\n",
    "\n",
    "y_pred = final_model.predict_proba(features_test)\n",
    "#y_pred = final_model.predict(features_test)\n",
    "#y_pred = final_model.predict(features_test)\n",
    "\n",
    "\n",
    "image_id = [i.split('/')[3] for i in list_images]\n",
    "\n",
    "submit = open('submit.SVM.csv','w')\n",
    "submit.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
    "\n",
    "for idx, id_n in enumerate(image_id):\n",
    "\tprobs=['%s' % p for p in list(y_pred[idx, :])]\n",
    "\tsubmit.write('%s,%s\\n' % (str(image_id[idx]),','.join(probs)))\n",
    "\n",
    "submit.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9 % 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
