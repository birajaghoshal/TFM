{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "POR HACER\n",
    "* funcion data augmentation y guardar las fotos creadas\n",
    "* cargar archivos txt, pickle o hd5py\n",
    "\n",
    "\n",
    "HECHOS\n",
    "* crear modelo cambiando la ultima capa y congelar capas a partir de la ultima convolucional\n",
    "* cargar pesos\n",
    "* compilar\n",
    "* muestras train, val y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.codesofinterest.com/2017/08/bottleneck-features-multi-class-classification-keras.html\n",
    "\n",
    "'''\n",
    "multiclasificacion\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150 # con el resize a 224 no funciona\n",
    "\n",
    "# top_model_weights_path = '../data/output_convnet/bottleneck_fc_model.h5'\n",
    "# train_data_dir = '../data/samples/train'\n",
    "# validation_data_dir = '../data/samples/validation'\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "\n",
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 1000\n",
    "epochs = 50\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es algo parecido a deepfeatures\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    \n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    print(\"se salva el archivo 1 y comienza el segundo generador\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    \n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "se salva el archivo 1 y comienza el segundo generador\n",
      "Found 1000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "ti_bn_features = time()\n",
    "\n",
    "save_bottlebeck_features()\n",
    "\n",
    "tf_bn_features = time()    \n",
    "\n",
    "tt_bn_features = tf_bn_features - ti_bn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:37\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # para que este punto\n",
    "# '''\n",
    "# the generator will only yield batches of image data, which is useful\n",
    "# to use model.predict_generator(),  model.evaluate_generator()\n",
    "# '''\n",
    "# train_labels = np.array(\n",
    "#         [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "# validation_labels = np.array(\n",
    "#         [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    \n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy','rb')) \n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(4096, activation='relu', name = \"fc1\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu', name = \"fc2\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='softmax', name = \"new_cats\"))\n",
    "\n",
    "#     model.compile(optimizer=SGD(), loss='categorical_crossentropy') # no arranca\n",
    "#     model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 29s 10ms/step - loss: 8.0212 - acc: 0.4990 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 27s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 27s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "ti_bn_train = time()\n",
    "\n",
    "train_top_model()\n",
    "\n",
    "tf_bn_train = time()    \n",
    "\n",
    "tt_bn_train = tf_bn_train - ti_bn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@srikar2097, I found the reason for that issue. \n",
    "flow_from_directory selects from one folder at a \n",
    "time and as there are more then 2000 images in the \n",
    "first folder (13k for me) it just takes images from one folder/class \n",
    "but still pretends like the val data is half from one class half from the other. See line 145.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:22:12\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39376169/keras-convolution2d-input-error-when-checking-model-input-expected-convolution\n",
    "img = load_img('my_img.jpg',False, (img_width, img_height))\n",
    "x = img_to_array(img)\n",
    "prediction = model.predict(x.reshape((1,3,img_width, img_height)),batch_size=32, verbose=0)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://stackoverflow.com/questions/36927025/how-to-use-keras-multi-layer-perceptron-for-multi-class-classification\n",
    "For multiclass prediction you need to convert your labels via to_categorical. \n",
    "https://github.com/keras-team/keras/blob/master/keras/utils/np_utils.py#L9\n",
    "\n",
    "\n",
    "For more info see this:\n",
    "\n",
    "http://stackoverflow.com/questions/36927025/how-to-use-keras-multi-layer-perceptron-for-multi-class-classification\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 8 # numero de categorias en las que clasificar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprobar si el modelo es vgg16 como el implementado en keras\n",
    "# https://github.com/keras-team/keras/blob/master/keras/applications/vgg16.py # estructura implementada en keras\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#top layer of the VGG net\n",
    "model.add(Dense(4096, activation='relu',name=\"fc1\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu',name=\"fc2\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax',name=\"last_layer\"))\n",
    "\n",
    "# model.summary() # lo oculto por ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"keras_weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "model.layers[-1].outbound_nodes = []\n",
    "\n",
    "# activacion softmax para calcular multiclasificacion\n",
    "model.add(Dense(n_categories, activation='softmax',name=\"new_cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# congelamos todas salvo las fc1 fc2 y new_cats, en estas los pesos se actualizaran (entrenaran)\n",
    "for layer in model.layers[:31]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.trainable:\n",
    "        print(\"layer {0:s} is trainable\".format(layer.name))\n",
    "    else:\n",
    "        print(\"layer {0:s} is freezed\".format(layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar estos hiperparametros --> leer sobre ellos y tomar decisiones\n",
    "# sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# compilamos este como el caso anterior para poder compararlos\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora ya hay que pasarle lista de fotografias a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "\n",
    "scores = []\n",
    "\n",
    "ti_bn_fit = time()\n",
    "\n",
    "for i, index_path in enumerate(img_list_train):\n",
    "    \n",
    "    # img preparation\n",
    "    img = image.load_img(index_path, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # model init\n",
    "#     model.fit(x, labels_train[i], verbose=1, validation_split=0.2)\n",
    "    model.fit(x, labels_train[i], verbose=1)\n",
    "\n",
    "    # model eval\n",
    "#     score = model.evaluate(x, labels_train[i], verbose=1)\n",
    "    \n",
    "#     scores.append(score[1] * 100)\n",
    "\n",
    "tf_bn_fit = time()    \n",
    "\n",
    "tt_bn_fit = tf_bn_fit - ti_bn_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_fit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "ti_bn_evaluate = time()\n",
    "\n",
    "model.evaluate(img_list_test, labels_test,verbose=1)\n",
    "\n",
    "tf_bn_evaluate = time()    \n",
    "\n",
    "tt_bn_evaluate = tf_bn_evaluate - ti_bn_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_evaluate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "ti_bn_predict = time()\n",
    "\n",
    "model.predict_classes(img_list_test,verbose=1)\n",
    "\n",
    "tf_bn_predict = time()    \n",
    "\n",
    "tt_bn_predict = tf_bn_predict - ti_bn_predictt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
