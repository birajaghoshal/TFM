{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "revisar pq se ha cambiado la forma de cargar pesos e implementar la red\n",
    "\n",
    "POR HACER\n",
    "* cargar archivos txt, pickle o hd5py (unificar)\n",
    "* refactorizar codigo\n",
    "* implementar bucle o funcion para leer el conjunto test y obtener la matriz de confusion\n",
    "* revisar codigo alternativa 1 y 2\n",
    "\n",
    "\n",
    "HECHOS\n",
    "* crear modelo cambiando la ultima capa y congelar capas a partir de la ultima convolucional\n",
    "* cargar pesos\n",
    "* compilar\n",
    "* muestras train, val y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentarios:\n",
    "\n",
    "* parametros a tunear\n",
    "    \n",
    "    * input de 150x150 mejora mucho frente a 224x224 (aunque se use bicubic o lanzcos)\n",
    "    * numero de capas y  cantidad 256 // 1024 // 2048 // 4096\n",
    "    * loss functions https://keras.io/losses/\n",
    "    * softmax (algunos autores incluso en multiclass usan sigmoid Â¿?)\n",
    "    * optimizer rmsprop (creo q es el apropiado) vs SGD con lr 0.01 y 0.001\n",
    "    \n",
    "mejores resultados con softmax (que creo que son los adecuados)\n",
    "\n",
    "1.- 1 capa dense de 256 sgd con lr 0.01 --> 88.60% con loss 0.3513\n",
    "\n",
    "2.- 1 capa dense de 256 rmsprop --> 89.1% con loss 0.8582\n",
    "\n",
    "3.- 2 capa dense de 1024 rmsprop --> 87.80% con loss 1.1068\n",
    "\n",
    "4.- 1 capa dense de 1024 rmsprop --> 89.70% con loss 1.0047\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.codesofinterest.com/2017/08/bottleneck-features-multi-class-classification-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = '../data/output_convnet/bottleneck_fc_model.h5'\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "test_data_dir = 'test'\n",
    "\n",
    "# number of epochs to train top model\n",
    "epochs = 50\n",
    "# batch size used by flow_from_directory and predict_generator\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    print(len(generator.filenames))\n",
    "    print(generator.class_indices)\n",
    "    print(len(generator.class_indices))\n",
    "\n",
    "    nb_train_samples = len(generator.filenames)\n",
    "    num_classes = len(generator.class_indices)\n",
    "\n",
    "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, predict_size_train)\n",
    "\n",
    "    np.save('../data/output_convnet/bottleneck_features_train.npy', bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    nb_validation_samples = len(generator.filenames)\n",
    "\n",
    "    predict_size_validation = int(\n",
    "        math.ceil(nb_validation_samples / batch_size))\n",
    "\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, predict_size_validation)\n",
    "\n",
    "    np.save('../data/output_convnet/bottleneck_features_validation.npy',\n",
    "            bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "3000\n",
      "{'01_TUMOR': 0, '02_STROMA': 1, '03_COMPLEX': 2, '04_LYMPHO': 3, '05_DEBRIS': 4, '06_MUCOSA': 5, '07_ADIPOSE': 6, '08_EMPTY': 7}\n",
      "8\n",
      "Found 1000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work\n",
    "\n",
    "ti_bn_features = time()\n",
    "\n",
    "save_bottlebeck_features()\n",
    "\n",
    "tf_bn_features = time()    \n",
    "\n",
    "tt_bn_features = tf_bn_features - ti_bn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:32\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "    generator_top = datagen_top.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    nb_train_samples = len(generator_top.filenames)\n",
    "    num_classes = len(generator_top.class_indices)\n",
    "\n",
    "    # save the class indices to use use later in predictions\n",
    "    np.save('../data/output_convnet/class_indices.npy', generator_top.class_indices)\n",
    "\n",
    "    # load the bottleneck features saved earlier\n",
    "    train_data = np.load('../data/output_convnet/bottleneck_features_train.npy')\n",
    "\n",
    "    # get the class lebels for the training data, in the original order\n",
    "    train_labels = generator_top.classes\n",
    "\n",
    "    # https://github.com/fchollet/keras/issues/3467\n",
    "    # convert the training labels to categorical vectors\n",
    "    train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "    generator_top = datagen_top.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    nb_validation_samples = len(generator_top.filenames)\n",
    "\n",
    "    validation_data = np.load('../data/output_convnet/bottleneck_features_validation.npy')\n",
    "\n",
    "    validation_labels = generator_top.classes\n",
    "    validation_labels = to_categorical(\n",
    "        validation_labels, num_classes=num_classes)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "#     model.add(Dense(4096, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "# #     model.add(Dense(8, activation='sigmoid'))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "#     model.add(Dense(2048, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(2048, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    model.compile(optimizer=SGD(lr=learning_rate),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     model.compile(optimizer='rmsprop',\n",
    "#                   loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    history = model.fit(train_data, train_labels,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(validation_data, validation_labels))\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "    (eval_loss, eval_accuracy) = model.evaluate(\n",
    "        validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "    print(\"[INFO] Loss: {}\".format(eval_loss))\n",
    "\n",
    "    plt.figure(1)\n",
    "\n",
    "    # summarize history for accuracy\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    # summarize history for loss\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 2s 564us/step - loss: 1.4991 - acc: 0.4507 - val_loss: 1.1149 - val_acc: 0.5300\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 1s 365us/step - loss: 1.0084 - acc: 0.6403 - val_loss: 0.7962 - val_acc: 0.7360\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.8493 - acc: 0.6983 - val_loss: 0.8611 - val_acc: 0.6500\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 1s 382us/step - loss: 0.7556 - acc: 0.7373 - val_loss: 0.6925 - val_acc: 0.7490\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 1s 383us/step - loss: 0.7112 - acc: 0.7393 - val_loss: 0.5919 - val_acc: 0.7800\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 1s 349us/step - loss: 0.6431 - acc: 0.7773 - val_loss: 0.5656 - val_acc: 0.7800\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 1s 374us/step - loss: 0.6212 - acc: 0.7803 - val_loss: 0.5363 - val_acc: 0.8160\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 1s 390us/step - loss: 0.5788 - acc: 0.7927 - val_loss: 0.5300 - val_acc: 0.8070\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 1s 381us/step - loss: 0.5694 - acc: 0.8040 - val_loss: 0.4789 - val_acc: 0.8230\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 1s 396us/step - loss: 0.5602 - acc: 0.8067 - val_loss: 0.4604 - val_acc: 0.8270\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 1s 370us/step - loss: 0.5186 - acc: 0.8100 - val_loss: 0.4950 - val_acc: 0.8170\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 1s 379us/step - loss: 0.5031 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8380\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 1s 370us/step - loss: 0.4825 - acc: 0.8363 - val_loss: 0.4135 - val_acc: 0.8460\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 1s 379us/step - loss: 0.4912 - acc: 0.8240 - val_loss: 0.4026 - val_acc: 0.8440\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.4794 - acc: 0.8287 - val_loss: 0.4273 - val_acc: 0.8490\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 1s 372us/step - loss: 0.4440 - acc: 0.8397 - val_loss: 0.4446 - val_acc: 0.8280\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 1s 374us/step - loss: 0.4470 - acc: 0.8373 - val_loss: 0.4097 - val_acc: 0.8550\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 1s 374us/step - loss: 0.4270 - acc: 0.8457 - val_loss: 0.4623 - val_acc: 0.8340\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 1s 377us/step - loss: 0.4253 - acc: 0.8493 - val_loss: 0.4461 - val_acc: 0.8350\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 1s 419us/step - loss: 0.4085 - acc: 0.8580 - val_loss: 0.3920 - val_acc: 0.8680\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 1s 377us/step - loss: 0.4005 - acc: 0.8603 - val_loss: 0.3689 - val_acc: 0.8590\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.3886 - acc: 0.8647 - val_loss: 0.3785 - val_acc: 0.8560\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 1s 369us/step - loss: 0.3732 - acc: 0.8693 - val_loss: 0.3881 - val_acc: 0.8570\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 1s 376us/step - loss: 0.3603 - acc: 0.8770 - val_loss: 0.3842 - val_acc: 0.8580\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 1s 392us/step - loss: 0.3657 - acc: 0.8690 - val_loss: 0.3822 - val_acc: 0.8560\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 1s 366us/step - loss: 0.3662 - acc: 0.8677 - val_loss: 0.3685 - val_acc: 0.8610\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 1s 387us/step - loss: 0.3440 - acc: 0.8803 - val_loss: 0.4173 - val_acc: 0.8530\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 1s 388us/step - loss: 0.3502 - acc: 0.8750 - val_loss: 0.3501 - val_acc: 0.8800\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 1s 384us/step - loss: 0.3476 - acc: 0.8807 - val_loss: 0.4764 - val_acc: 0.8420\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 1s 382us/step - loss: 0.3215 - acc: 0.8917 - val_loss: 0.3896 - val_acc: 0.8640\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 1s 370us/step - loss: 0.3191 - acc: 0.8893 - val_loss: 0.3519 - val_acc: 0.8790\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 1s 394us/step - loss: 0.3286 - acc: 0.8823 - val_loss: 0.3395 - val_acc: 0.8800\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 1s 370us/step - loss: 0.2992 - acc: 0.8957 - val_loss: 0.3574 - val_acc: 0.8720\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 1s 385us/step - loss: 0.3151 - acc: 0.8930 - val_loss: 0.3518 - val_acc: 0.8760\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 1s 380us/step - loss: 0.3006 - acc: 0.8940 - val_loss: 0.3955 - val_acc: 0.8540\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 1s 375us/step - loss: 0.2870 - acc: 0.8967 - val_loss: 0.3271 - val_acc: 0.8850\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 1s 389us/step - loss: 0.2757 - acc: 0.9053 - val_loss: 0.3456 - val_acc: 0.8730\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 1s 384us/step - loss: 0.2885 - acc: 0.8990 - val_loss: 0.3517 - val_acc: 0.8710\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 1s 393us/step - loss: 0.2753 - acc: 0.9083 - val_loss: 0.3753 - val_acc: 0.8670\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 1s 370us/step - loss: 0.2553 - acc: 0.9087 - val_loss: 0.3844 - val_acc: 0.8620\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 1s 400us/step - loss: 0.2661 - acc: 0.9070 - val_loss: 0.3521 - val_acc: 0.8750\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 1s 378us/step - loss: 0.2631 - acc: 0.9130 - val_loss: 0.3509 - val_acc: 0.8780\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 1s 390us/step - loss: 0.2580 - acc: 0.9093 - val_loss: 0.4043 - val_acc: 0.8530\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 1s 384us/step - loss: 0.2357 - acc: 0.9227 - val_loss: 0.3616 - val_acc: 0.8780\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 1s 354us/step - loss: 0.2386 - acc: 0.9130 - val_loss: 0.4834 - val_acc: 0.8300\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.2459 - acc: 0.9177 - val_loss: 0.3567 - val_acc: 0.8850\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 1s 386us/step - loss: 0.2330 - acc: 0.9230 - val_loss: 0.3252 - val_acc: 0.8800\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 1s 394us/step - loss: 0.2366 - acc: 0.9170 - val_loss: 0.3467 - val_acc: 0.8800\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 1s 382us/step - loss: 0.2282 - acc: 0.9240 - val_loss: 0.3562 - val_acc: 0.8740\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 1s 371us/step - loss: 0.2177 - acc: 0.9237 - val_loss: 0.3513 - val_acc: 0.8860\n",
      "1000/1000 [==============================] - 0s 126us/step\n",
      "[INFO] accuracy: 88.60%\n",
      "[INFO] Loss: 0.3513415638968581\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9db81e1a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work\n",
    "\n",
    "ti_bn_train = time()\n",
    "\n",
    "train_top_model()\n",
    "\n",
    "tf_bn_train = time()    \n",
    "\n",
    "tt_bn_train = tf_bn_train - ti_bn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:58\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    # load the class_indices saved in the earlier step\n",
    "    class_dictionary = np.load('class_indices.npy').item()\n",
    "\n",
    "    num_classes = len(class_dictionary)\n",
    "\n",
    "    # add the path to your test image below\n",
    "    image_path = test_data_dir\n",
    "\n",
    "    orig = cv2.imread(image_path)\n",
    "\n",
    "    print(\"[INFO] loading and preprocessing image...\")\n",
    "    image = load_img(image_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "\n",
    "################################################\n",
    "#     #pre procesado de imagen\n",
    "#     img = image.load_img(img_path, target_size=(224, 224), interpolation='lanczos')\n",
    "#     x = image.img_to_array(img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "#     x = preprocess_input(x)\n",
    "################################################\n",
    "\n",
    "    # important! otherwise the predictions will be '0'\n",
    "    image = image / 255\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # get the bottleneck prediction from the pre-trained VGG16 model\n",
    "    bottleneck_prediction = model.predict(image)\n",
    "\n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=bottleneck_prediction.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "    model.load_weights(top_model_weights_path)\n",
    "\n",
    "    # use the bottleneck prediction on the top model to get the final\n",
    "    # classification\n",
    "    class_predicted = model.predict_classes(bottleneck_prediction)\n",
    "\n",
    "    probabilities = model.predict_proba(bottleneck_prediction)\n",
    "\n",
    "    inID = class_predicted[0]\n",
    "\n",
    "    inv_map = {v: k for k, v in class_dictionary.items()}\n",
    "\n",
    "    label = inv_map[inID]\n",
    "\n",
    "    # get the prediction label\n",
    "    print(\"Image ID: {}, Label: {}\".format(inID, label))\n",
    "\n",
    "    # display the predictions with the image\n",
    "    cv2.putText(orig, \"Predicted: {}\".format(label), (10, 30),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 1.5, (43, 99, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Classification\", orig)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternativa 1 no funciona correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150 # con el resize a 224 no funciona\n",
    "\n",
    "# top_model_weights_path = '../data/output_convnet/bottleneck_fc_model.h5'\n",
    "# train_data_dir = '../data/samples/train'\n",
    "# validation_data_dir = '../data/samples/validation'\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "\n",
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 1000\n",
    "epochs = 50\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es algo parecido a deepfeatures\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    \n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    print(\"se salva el archivo 1 y comienza el segundo generador\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    \n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_bn_features = time()\n",
    "\n",
    "save_bottlebeck_features()\n",
    "\n",
    "tf_bn_features = time()    \n",
    "\n",
    "tt_bn_features = tf_bn_features - ti_bn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # para que este punto\n",
    "# '''\n",
    "# the generator will only yield batches of image data, which is useful\n",
    "# to use model.predict_generator(),  model.evaluate_generator()\n",
    "# '''\n",
    "# train_labels = np.array(\n",
    "#         [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "# validation_labels = np.array(\n",
    "#         [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    \n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy','rb')) \n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(4096, activation='relu', name = \"fc1\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu', name = \"fc2\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='softmax', name = \"new_cats\"))\n",
    "\n",
    "#     model.compile(optimizer=SGD(), loss='categorical_crossentropy') # no arranca\n",
    "#     model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    my_sgd = SGD(lr=0.001)\n",
    "    model.compile(optimizer=my_sgd,\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "ti_bn_train = time()\n",
    "\n",
    "train_top_model()\n",
    "\n",
    "tf_bn_train = time()    \n",
    "\n",
    "tt_bn_train = tf_bn_train - ti_bn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@srikar2097, I found the reason for that issue. \n",
    "flow_from_directory selects from one folder at a \n",
    "time and as there are more then 2000 images in the \n",
    "first folder (13k for me) it just takes images from one folder/class \n",
    "but still pretends like the val data is half from one class half from the other. See line 145.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39376169/keras-convolution2d-input-error-when-checking-model-input-expected-convolution\n",
    "img = load_img('my_img.jpg',False, (img_width, img_height))\n",
    "x = img_to_array(img)\n",
    "prediction = model.predict(x.reshape((1,3,img_width, img_height)),batch_size=32, verbose=0)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://stackoverflow.com/questions/36927025/how-to-use-keras-multi-layer-perceptron-for-multi-class-classification\n",
    "For multiclass prediction you need to convert your labels via to_categorical. \n",
    "https://github.com/keras-team/keras/blob/master/keras/utils/np_utils.py#L9\n",
    "\n",
    "\n",
    "For more info see this:\n",
    "\n",
    "http://stackoverflow.com/questions/36927025/how-to-use-keras-multi-layer-perceptron-for-multi-class-classification\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternativa 2 no funciona correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 8 # numero de categorias en las que clasificar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprobar si el modelo es vgg16 como el implementado en keras\n",
    "# https://github.com/keras-team/keras/blob/master/keras/applications/vgg16.py # estructura implementada en keras\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#top layer of the VGG net\n",
    "model.add(Dense(4096, activation='relu',name=\"fc1\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu',name=\"fc2\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax',name=\"last_layer\"))\n",
    "\n",
    "# model.summary() # lo oculto por ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"keras_weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "model.layers[-1].outbound_nodes = []\n",
    "\n",
    "# activacion softmax para calcular multiclasificacion\n",
    "model.add(Dense(n_categories, activation='softmax',name=\"new_cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# congelamos todas salvo las fc1 fc2 y new_cats, en estas los pesos se actualizaran (entrenaran)\n",
    "for layer in model.layers[:31]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.trainable:\n",
    "        print(\"layer {0:s} is trainable\".format(layer.name))\n",
    "    else:\n",
    "        print(\"layer {0:s} is freezed\".format(layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar estos hiperparametros --> leer sobre ellos y tomar decisiones\n",
    "# sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# compilamos este como el caso anterior para poder compararlos\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora ya hay que pasarle lista de fotografias a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "\n",
    "scores = []\n",
    "\n",
    "ti_bn_fit = time()\n",
    "\n",
    "for i, index_path in enumerate(img_list_train):\n",
    "    \n",
    "    # img preparation\n",
    "    img = image.load_img(index_path, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # model init\n",
    "#     model.fit(x, labels_train[i], verbose=1, validation_split=0.2)\n",
    "    model.fit(x, labels_train[i], verbose=1)\n",
    "\n",
    "    # model eval\n",
    "#     score = model.evaluate(x, labels_train[i], verbose=1)\n",
    "    \n",
    "#     scores.append(score[1] * 100)\n",
    "\n",
    "tf_bn_fit = time()    \n",
    "\n",
    "tt_bn_fit = tf_bn_fit - ti_bn_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_fit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "ti_bn_evaluate = time()\n",
    "\n",
    "model.evaluate(img_list_test, labels_test,verbose=1)\n",
    "\n",
    "tf_bn_evaluate = time()    \n",
    "\n",
    "tt_bn_evaluate = tf_bn_evaluate - ti_bn_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_evaluate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "ti_bn_predict = time()\n",
    "\n",
    "model.predict_classes(img_list_test,verbose=1)\n",
    "\n",
    "tf_bn_predict = time()    \n",
    "\n",
    "tt_bn_predict = tf_bn_predict - ti_bn_predictt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
