{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoras\n",
    "\n",
    "POR HACER\n",
    "* implementar bucle o funcion para leer el conjunto test y obtener la matriz de confusion (lo mas importante por ahora) --> ERROR\n",
    "* refactorizar codigo\n",
    "* revisar codigo alternativa 1 y 2\n",
    "\n",
    "\n",
    "HECHOS\n",
    "* crear modelo cambiando la ultima capa y congelar capas a partir de la ultima convolucional\n",
    "* cargar pesos\n",
    "* compilar\n",
    "* muestras train, val y test\n",
    "\n",
    "\n",
    "Comentarios:\n",
    "\n",
    "* parametros a tunear\n",
    "    \n",
    "    * input de 150x150 mejora mucho frente a 224x224 (aunque se use bicubic o lanzcos)\n",
    "    * numero de capas y  cantidad 256 // 1024 // 2048 // 4096\n",
    "    * loss functions https://keras.io/losses/\n",
    "    * softmax (algunos autores incluso en multiclass usan sigmoid Â¿?)\n",
    "    * optimizer rmsprop (creo q es el apropiado) vs SGD con lr 0.01 y 0.001\n",
    "    \n",
    "mejores resultados con softmax (que creo que son los adecuados)\n",
    "\n",
    "1.- 1 capa dense de 256 sgd con lr 0.001 --> 86.70% con loss 0.3859 --> ELEGIDA ENTRE TODAS LAS ARQUITECTURAS, en dfmap lr = 0.01\n",
    "\n",
    "2.- 1 capa dense de 256 rmsprop --> 89.1% con loss 0.8582\n",
    "\n",
    "3.- 2 capa dense de 1024 rmsprop --> 87.80% con loss 1.1068\n",
    "\n",
    "4.- 1 capa dense de 1024 rmsprop --> 89.70% con loss 1.0047\n",
    "\n",
    "ref\n",
    "\n",
    "http://www.codesofinterest.com/2017/08/bottleneck-features-multi-class-classification-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "# import os\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = \"train\"  \n",
    "validation_data_dir = \"validation\"\n",
    "test_data_dir = \"test\"\n",
    "\n",
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "00:00:31\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ti_bn_features = time.time()\n",
    "\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "'''\n",
    "https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L1002\n",
    "if PIL version 1.1.3 interpolation = 'lanczos'\n",
    "else interpolation = 'bicubic' \n",
    "''' \n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = None,\n",
    "    shuffle = False)\n",
    "\n",
    "nb_train_samples = len(generator.filenames)  \n",
    "num_classes = len(generator.class_indices)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n",
    "\n",
    "bnfeatures_train = model.predict_generator(\n",
    "    generator, predict_size_train)\n",
    "\n",
    "# np.save('../data/output_convnet/bnfeatures_train.npy', bnfeatures_train)\n",
    "np.save('bnfeatures_train.npy', bnfeatures_train)\n",
    "\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "nb_validation_samples = len(generator.filenames)\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
    "   \n",
    "bnfeatures_val = model.predict_generator(  \n",
    "     generator, predict_size_validation)\n",
    "\n",
    "# np.save('../data/output_convnet/bnfeatures_val.npy', bnfeatures_val)\n",
    "np.save('bnfeatures_val.npy', bnfeatures_val)\n",
    "\n",
    "\n",
    "tf_bn_features = time.time()    \n",
    "tt_bn_features = tf_bn_features - ti_bn_features\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator\n",
    "# print(type(generator)) # type class\n",
    "# print(len(generator.filenames)) # number of imgs in train folder\n",
    "# print(generator.class_indices) # categories\n",
    "# print(len(generator.class_indices)) # number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_2 to have shape (None, 8) but got array with shape (3000, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1a751526701e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m           validation_data=(validation_data, validation_labels))\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bn_VGG16_model_test.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have shape (None, 8) but got array with shape (3000, 1)"
     ]
    }
   ],
   "source": [
    "train_data = np.load(open('bnfeatures_train.npy','rb'))\n",
    "train_labels = np.array(\n",
    "    [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "validation_data = np.load(open('bnfeatures_val.npy','rb'))\n",
    "validation_labels = np.array(\n",
    "    [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "\n",
    "model.save_weights(\"bn_VGG16_model_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_bn_train = time.time()\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(\n",
    "    train_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode='categorical',  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_train_samples = len(generator_top.filenames)  \n",
    "num_classes = len(generator_top.class_indices)  \n",
    "\n",
    "# load the bottleneck features saved earlier  \n",
    "# train_data = np.load('../data/output_convnet/bnfeatures_train.npy')\n",
    "train_data = np.load('bnfeatures_train.npy')\n",
    "\n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = generator_top.classes  \n",
    "\n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(  \n",
    "    validation_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode=None,  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "\n",
    "validation_data = np.load('../data/output_convnet/bnfeatures_val.npy')  \n",
    "validation_data = np.load('bnfeatures_val.npy')  \n",
    "\n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# top model\n",
    "model = Sequential()  \n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
    "model.add(Dense(256, activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels))  \n",
    "\n",
    "# model.save_weights('../data/output_convnet/bn_VGG16_model.h5')  \n",
    "model.save_weights('bn_VGG16_model.h5')  \n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(\n",
    "    validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"acc: {:.2f}%\".format(eval_accuracy * 100))  \n",
    "print(\"loss: {}\".format(eval_loss))\n",
    "\n",
    "plt.figure(1)  \n",
    "   \n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "plt.show()\n",
    "\n",
    "tf_bn_train = time.time()    \n",
    "tt_bn_train = tf_bn_train - ti_bn_train\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "# hdf5_file = h5py.File('../data/output_convnet/bn_VGG16_model.h5', mode='r')\n",
    "hdf5_file = h5py.File('bn_VGG16_model.h5', mode='r')\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# listado del train\n",
    "img_test_real = []\n",
    "img_cat_real = [] # conf mat\n",
    "img_cat_pred = [] # conf mat\n",
    "\n",
    "img_folder = sorted([folder for folder in os.listdir(test_data_dir)\n",
    "                  if os.path.isdir(os.path.join(test_data_dir, folder))])\n",
    "\n",
    "for index_folder, category in enumerate(img_folder):\n",
    "    \n",
    "    folder = os.path.join(test_data_dir, category)\n",
    "\n",
    "    for index_img, img in enumerate(os.listdir(folder)):\n",
    "        \n",
    "        if img.endswith(\".tif\"): # just in case there are other kind of files like .db\n",
    "            img_test_real.append(os.path.join(folder, img))\n",
    "            img_cat_real.append(img_folder[index_folder])\n",
    "\n",
    "    print(\"Category {0:s} has {1:d} images.\".format(category, index_img+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "# from keras import backend as K\n",
    "\n",
    "\n",
    "class_dictionary = np.load(\"../data/output_convnet/class_indices.npy\").item()\n",
    "num_classes = len(class_dictionary)\n",
    "\n",
    "image_path = \"test/\"\n",
    "\n",
    "\n",
    "# init time\n",
    "ti_pred = time.time()\n",
    "\n",
    "for index, img in enumerate(img_test_real):\n",
    "    \n",
    "    if not index % 100:\n",
    "        print(\"image {0:d} processed\".format(index))\n",
    "    \n",
    "    # pre process\n",
    "    img = image.load_img(img, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "#     x = x / 255\n",
    "    \n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    \n",
    "    model = VGG16(include_top=False, weights='imagenet')\n",
    "    bn_prediction = model.predict(x)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=bn_prediction.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    \n",
    "    model.load_weights(\"../data/output_convnet/bn_VGG16_model.h5\") \n",
    "\n",
    "    class_predicted = model.predict_classes(bn_prediction)\n",
    "\n",
    "    inID = class_predicted[0]  \n",
    "   \n",
    "    class_dictionary = generator_top.class_indices  \n",
    "   \n",
    "    inv_map = {v: k for k, v in class_dictionary.items()}  \n",
    "   \n",
    "    label = inv_map[inID] \n",
    "    \n",
    "    img_cat_pred.append(label)\n",
    "    \n",
    "# stop time\n",
    "tf_pred = time.time()    \n",
    "tt_pred = tf_pred - ti_pred\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
