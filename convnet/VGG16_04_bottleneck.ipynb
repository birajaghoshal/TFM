{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "POR HACER\n",
    "* funcion data augmentation y guardar las fotos creadas\n",
    "* cargar archivos txt, pickle o hd5py\n",
    "\n",
    "\n",
    "HECHOS\n",
    "* crear modelo cambiando la ultima capa y congelar capas a partir de la ultima convolucional\n",
    "* cargar pesos\n",
    "* compilar\n",
    "* muestras train, val y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../system/functions.ipynb' # import util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_labels & img_list - completed path to file\n",
    "PATH_TO_LABELS_FILE = \"../data/output_dataset/img_labels\"\n",
    "PATH_TO_PATHS_FILE = \"../data/output_dataset/img_list\"\n",
    "\n",
    "# output convnet files path + feed\n",
    "PATH_TO_OUTPUT = \"../data/output_convnet\"\n",
    "PATH_TO_DATA_AUGMENTATION = \"../data/output_dataset/data_augmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = []\n",
    "img_list = []\n",
    "\n",
    "'''\n",
    "para eliminar el retorno de carro --> [:-1]\n",
    "para encontrar el path correcto hay que transformar \n",
    "la ruta puesto que este fichero y desde el que se crea tienen rutas distintas\n",
    "'''\n",
    "# input_dataset/01_TUMOR/2642_CRC-Prim-HE-07_025.tif_Row_1351_Col_601.tif\n",
    "\n",
    "with open(PATH_TO_LABELS_FILE,'r') as f_img_labels:\n",
    "    for line in f_img_labels:\n",
    "        img_labels.append(line[:-1]) \n",
    "\n",
    "with open(PATH_TO_PATHS_FILE,'r') as f_img_list:\n",
    "    for line in f_img_list:\n",
    "        img_list.append(\"../data/\"+line[:-1]) # para eliminar el retorno de carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_labels_arr = np.array(img_labels)\n",
    "img_list_arr = np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proporciones elegidas 80-20 // entrenamiento y test\n",
    "TRAIN = 0.8\n",
    "\n",
    "# index selection\n",
    "index_selection = np.arange(len(img_list)) # tamaño de la lista\n",
    "\n",
    "np.random.shuffle(index_selection) # ahora en index_selection tenemos aleatorizado el vector\n",
    "\n",
    "# ahora tenemos aleatorizados los vectores de la misma manera (pareados)\n",
    "\n",
    "img_labels_arr_rand = img_labels_arr[index_selection]\n",
    "img_list_arr_rand = img_list_arr[index_selection]\n",
    "\n",
    "sep = int(TRAIN*len(img_list)) # [0:3999] -> 4000 images to train (validation included)\n",
    "\n",
    "# print(sep)\n",
    "\n",
    "\n",
    "# muestras de entrenamiento\n",
    "\n",
    "labels_train = img_labels_arr_rand[:sep] \n",
    "img_list_train = img_list_arr_rand[:sep]\n",
    "\n",
    "# muestras test\n",
    "\n",
    "labels_test = img_labels_arr_rand[int(sep):] # 2999 +1 to 2999+1+1000\n",
    "img_list_test = img_list_arr_rand[int(sep):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # proporciones elegidas 60-20-20 // entrenamiento validacion y test\n",
    "# TRAIN = 0.8\n",
    "\n",
    "# # index selection\n",
    "# index_selection = np.arange(len(img_list)) # tamaño de la lista\n",
    "\n",
    "# np.random.shuffle(index_selection) # ahora en index_selection tenemos aleatorizado el vector\n",
    "\n",
    "# # ahora tenemos aleatorizados los vectores de la misma manera (pareados)\n",
    "\n",
    "# img_labels_arr_rand = img_labels_arr[index_selection]\n",
    "# img_list_arr_rand = img_list_arr[index_selection]\n",
    "\n",
    "# sep = int(TRAIN*len(img_list)) # [0:3999] -> 4000 images to train (validation included)\n",
    "\n",
    "# # print(sep)\n",
    "\n",
    "\n",
    "# # muestras de entrenamiento\n",
    "\n",
    "# labels_train = img_labels_arr_rand[:sep] \n",
    "# img_list_train = img_list_arr_rand[:sep]\n",
    "\n",
    "# # muestras test\n",
    "\n",
    "# labels_test = img_labels_arr_rand[int(sep):] # 2999 +1 to 2999+1+1000\n",
    "# img_list_test = img_list_arr_rand[int(sep):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando train_test_split de scikit learn\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño muestra entrenamiento\n",
      "4000\n",
      "4000\n",
      "\n",
      "tamaño muestra test\n",
      "1000\n",
      "1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"tamaño muestra entrenamiento\")\n",
    "print(labels_train.shape[0])\n",
    "print(img_list_train.shape[0])\n",
    "print()\n",
    "\n",
    "print(\"tamaño muestra test\")\n",
    "print(labels_test.shape[0])\n",
    "print(img_list_test.shape[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos, que las etiquetas se correspondan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels_train)\n",
    "# print(img_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels_test)\n",
    "# print(img_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copiamos las fotos en dos directorios para alimentar a la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BORRAR LAS FOTOS SI GENERAMOS OTRA VEZ LAS MUESTRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# for img in img_list_train:\n",
    "#     shutil.copy(img, 'train/')\n",
    "    \n",
    "# for img in img_list_test:\n",
    "#     shutil.copy(img, 'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 8 # numero de categorias en las que clasificar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprobar si el modelo es vgg16 como el implementado en keras\n",
    "# https://github.com/keras-team/keras/blob/master/keras/applications/vgg16.py # estructura implementada en keras\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#top layer of the VGG net\n",
    "model.add(Dense(4096, activation='relu',name=\"fc1\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu',name=\"fc2\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax',name=\"last_layer\"))\n",
    "\n",
    "# model.summary() # lo oculto por ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"keras_weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "model.layers[-1].outbound_nodes = []\n",
    "\n",
    "# activacion softmax para calcular multiclasificacion\n",
    "model.add(Dense(n_categories, activation='softmax',name=\"new_cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# congelamos todas salvo las fc1 fc2 y new_cats, en estas los pesos se actualizaran (entrenaran)\n",
    "for layer in model.layers[:31]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.trainable:\n",
    "        print(\"layer {0:s} is trainable\".format(layer.name))\n",
    "    else:\n",
    "        print(\"layer {0:s} is freezed\".format(layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar estos hiperparametros --> leer sobre ellos y tomar decisiones\n",
    "# sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# compilamos este como el caso anterior para poder compararlos\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora ya hay que pasarle lista de fotografias a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "\n",
    "scores = []\n",
    "\n",
    "ti_bn_fit = time()\n",
    "\n",
    "for i, index_path in enumerate(img_list_train):\n",
    "    \n",
    "    # img preparation\n",
    "    img = image.load_img(index_path, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # model init\n",
    "#     model.fit(x, labels_train[i], verbose=1, validation_split=0.2)\n",
    "    model.fit(x, labels_train[i], verbose=1)\n",
    "\n",
    "    # model eval\n",
    "#     score = model.evaluate(x, labels_train[i], verbose=1)\n",
    "    \n",
    "#     scores.append(score[1] * 100)\n",
    "\n",
    "tf_bn_fit = time()    \n",
    "\n",
    "tt_bn_fit = tf_bn_fit - ti_bn_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_fit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "ti_bn_evaluate = time()\n",
    "\n",
    "model.evaluate(img_list_test, labels_test,verbose=1)\n",
    "\n",
    "tf_bn_evaluate = time()    \n",
    "\n",
    "tt_bn_evaluate = tf_bn_evaluate - ti_bn_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_evaluate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/models/sequential/\n",
    "ti_bn_predict = time()\n",
    "\n",
    "model.predict_classes(img_list_test,verbose=1)\n",
    "\n",
    "tf_bn_predict = time()    \n",
    "\n",
    "tt_bn_predict = tf_bn_predict - ti_bn_predictt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
