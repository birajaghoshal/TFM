{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoras\n",
    "\n",
    "POR HACER\n",
    "* implementar bucle o funcion para leer el conjunto test y obtener la matriz de confusion (lo mas importante por ahora) --> ERROR\n",
    "* refactorizar codigo\n",
    "* revisar codigo alternativa 1 y 2\n",
    "\n",
    "\n",
    "HECHOS\n",
    "* crear modelo cambiando la ultima capa y congelar capas a partir de la ultima convolucional\n",
    "* cargar pesos\n",
    "* compilar\n",
    "* muestras train, val y test\n",
    "\n",
    "\n",
    "Comentarios:\n",
    "\n",
    "* parametros a tunear\n",
    "    \n",
    "    * input de 150x150 mejora mucho frente a 224x224 (aunque se use bicubic o lanzcos)\n",
    "    * numero de capas y  cantidad 256 // 1024 // 2048 // 4096\n",
    "    * loss functions https://keras.io/losses/\n",
    "    * softmax (algunos autores incluso en multiclass usan sigmoid Â¿?)\n",
    "    * optimizer rmsprop (creo q es el apropiado) vs SGD con lr 0.01 y 0.001\n",
    "    \n",
    "mejores resultados con softmax (que creo que son los adecuados)\n",
    "\n",
    "1.- 1 capa dense de 256 sgd con lr 0.001 --> 86.70% con loss 0.3859 --> ELEGIDA ENTRE TODAS LAS ARQUITECTURAS, en dfmap lr = 0.01\n",
    "\n",
    "2.- 1 capa dense de 256 rmsprop --> 89.1% con loss 0.8582\n",
    "\n",
    "3.- 2 capa dense de 1024 rmsprop --> 87.80% con loss 1.1068\n",
    "\n",
    "4.- 1 capa dense de 1024 rmsprop --> 89.70% con loss 1.0047\n",
    "\n",
    "ref\n",
    "\n",
    "http://www.codesofinterest.com/2017/08/bottleneck-features-multi-class-classification-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "# import os\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = \"train\"  \n",
    "validation_data_dir = \"validation\"\n",
    "test_data_dir = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "00:00:33\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ti_bn_features = time.time()\n",
    "\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "'''\n",
    "https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L1002\n",
    "if PIL version 1.1.3 interpolation = 'lanczos'\n",
    "else interpolation = 'bicubic' \n",
    "''' \n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = None,\n",
    "    shuffle = False,\n",
    "    interpolation = 'lanczos')\n",
    "\n",
    "\n",
    "\n",
    "nb_train_samples = len(generator.filenames)  \n",
    "num_classes = len(generator.class_indices)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n",
    "\n",
    "bnfeatures_train = model.predict_generator(\n",
    "    generator, predict_size_train)\n",
    "\n",
    "np.save('../data/output_convnet/bnfeatures_train.npy', bnfeatures_train)\n",
    "\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')\n",
    "\n",
    "nb_validation_samples = len(generator.filenames)\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
    "   \n",
    "bnfeatures_val = model.predict_generator(  \n",
    "     generator, predict_size_validation)\n",
    "\n",
    "np.save('../data/output_convnet/bnfeatures_val.npy', bnfeatures_val)\n",
    "\n",
    "        \n",
    "tf_bn_features = time.time()    \n",
    "tt_bn_features = tf_bn_features - ti_bn_features\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator\n",
    "# print(type(generator)) # type class\n",
    "# print(len(generator.filenames)) # number of imgs in train folder\n",
    "# print(generator.class_indices) # categories\n",
    "# print(len(generator.class_indices)) # number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 1s 452us/step - loss: 1.6501 - acc: 0.4013 - val_loss: 1.3138 - val_acc: 0.5730\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 1s 324us/step - loss: 1.2331 - acc: 0.5800 - val_loss: 1.0359 - val_acc: 0.7120\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 1s 356us/step - loss: 1.0695 - acc: 0.6410 - val_loss: 0.9357 - val_acc: 0.7040\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 1s 285us/step - loss: 0.9394 - acc: 0.6883 - val_loss: 0.8418 - val_acc: 0.7530\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 1s 328us/step - loss: 0.8857 - acc: 0.7063 - val_loss: 0.7563 - val_acc: 0.7860\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 1s 366us/step - loss: 0.8113 - acc: 0.7433 - val_loss: 0.7316 - val_acc: 0.7710\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 1s 343us/step - loss: 0.7814 - acc: 0.7453 - val_loss: 0.6866 - val_acc: 0.7920\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 1s 349us/step - loss: 0.7261 - acc: 0.7680 - val_loss: 0.6346 - val_acc: 0.8160\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 1s 335us/step - loss: 0.7000 - acc: 0.7670 - val_loss: 0.6375 - val_acc: 0.7930\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 1s 296us/step - loss: 0.6723 - acc: 0.7790 - val_loss: 0.5939 - val_acc: 0.8130\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.6491 - acc: 0.7880 - val_loss: 0.5731 - val_acc: 0.8190\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 1s 297us/step - loss: 0.6406 - acc: 0.7950 - val_loss: 0.5918 - val_acc: 0.8040\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 1s 307us/step - loss: 0.6088 - acc: 0.8047 - val_loss: 0.5530 - val_acc: 0.8170\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 1s 349us/step - loss: 0.5941 - acc: 0.8143 - val_loss: 0.5411 - val_acc: 0.8220\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 1s 366us/step - loss: 0.5834 - acc: 0.8110 - val_loss: 0.5319 - val_acc: 0.8280\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 1s 375us/step - loss: 0.5763 - acc: 0.8130 - val_loss: 0.5158 - val_acc: 0.8310\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 1s 337us/step - loss: 0.5568 - acc: 0.8220 - val_loss: 0.5048 - val_acc: 0.8370\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 1s 328us/step - loss: 0.5471 - acc: 0.8230 - val_loss: 0.4928 - val_acc: 0.8440\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 1s 353us/step - loss: 0.5352 - acc: 0.8253 - val_loss: 0.5067 - val_acc: 0.8360\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 1s 340us/step - loss: 0.5340 - acc: 0.8290 - val_loss: 0.4901 - val_acc: 0.8380\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 1s 368us/step - loss: 0.5163 - acc: 0.8380 - val_loss: 0.4744 - val_acc: 0.8430\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 1s 383us/step - loss: 0.5083 - acc: 0.8367 - val_loss: 0.4616 - val_acc: 0.8510\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 1s 359us/step - loss: 0.4995 - acc: 0.8340 - val_loss: 0.4617 - val_acc: 0.8490\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 1s 342us/step - loss: 0.4981 - acc: 0.8307 - val_loss: 0.4656 - val_acc: 0.8470\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 1s 361us/step - loss: 0.4855 - acc: 0.8430 - val_loss: 0.4633 - val_acc: 0.8480\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 1s 361us/step - loss: 0.4768 - acc: 0.8480 - val_loss: 0.4707 - val_acc: 0.8420\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 1s 358us/step - loss: 0.4698 - acc: 0.8343 - val_loss: 0.4452 - val_acc: 0.8540\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 1s 366us/step - loss: 0.4757 - acc: 0.8450 - val_loss: 0.4528 - val_acc: 0.8430\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 1s 364us/step - loss: 0.4522 - acc: 0.8590 - val_loss: 0.4383 - val_acc: 0.8460\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.4536 - acc: 0.8473 - val_loss: 0.4319 - val_acc: 0.8560\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 1s 372us/step - loss: 0.4501 - acc: 0.8507 - val_loss: 0.4443 - val_acc: 0.8460\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 1s 381us/step - loss: 0.4458 - acc: 0.8527 - val_loss: 0.4306 - val_acc: 0.8510\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 1s 353us/step - loss: 0.4146 - acc: 0.8660 - val_loss: 0.4303 - val_acc: 0.8460\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 1s 361us/step - loss: 0.4339 - acc: 0.8643 - val_loss: 0.4179 - val_acc: 0.8650\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 1s 369us/step - loss: 0.4179 - acc: 0.8590 - val_loss: 0.4202 - val_acc: 0.8550\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 1s 340us/step - loss: 0.4105 - acc: 0.8620 - val_loss: 0.4404 - val_acc: 0.8430\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 1s 350us/step - loss: 0.4110 - acc: 0.8673 - val_loss: 0.4292 - val_acc: 0.8480\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 1s 384us/step - loss: 0.4060 - acc: 0.8677 - val_loss: 0.4036 - val_acc: 0.8670\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 1s 349us/step - loss: 0.4095 - acc: 0.8767 - val_loss: 0.4145 - val_acc: 0.8590\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.4013 - acc: 0.8713 - val_loss: 0.4082 - val_acc: 0.8610\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 1s 359us/step - loss: 0.4012 - acc: 0.8717 - val_loss: 0.4167 - val_acc: 0.8580\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 1s 344us/step - loss: 0.3929 - acc: 0.8717 - val_loss: 0.4079 - val_acc: 0.8540\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 1s 368us/step - loss: 0.3869 - acc: 0.8737 - val_loss: 0.4136 - val_acc: 0.8490\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 1s 340us/step - loss: 0.3734 - acc: 0.8827 - val_loss: 0.3987 - val_acc: 0.8590\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 1s 374us/step - loss: 0.3793 - acc: 0.8827 - val_loss: 0.3927 - val_acc: 0.8650\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 1s 355us/step - loss: 0.3721 - acc: 0.8833 - val_loss: 0.4021 - val_acc: 0.8640\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 1s 360us/step - loss: 0.3660 - acc: 0.8820 - val_loss: 0.3908 - val_acc: 0.8630\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 1s 372us/step - loss: 0.3703 - acc: 0.8757 - val_loss: 0.3892 - val_acc: 0.8720\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 1s 374us/step - loss: 0.3643 - acc: 0.8863 - val_loss: 0.3811 - val_acc: 0.8720\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 1s 359us/step - loss: 0.3641 - acc: 0.8843 - val_loss: 0.3859 - val_acc: 0.8670\n",
      "1000/1000 [==============================] - 0s 116us/step\n",
      "\n",
      "\n",
      "acc: 86.70%\n",
      "loss: 0.3859377719759941\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5fc5adc630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:53\n"
     ]
    }
   ],
   "source": [
    "ti_bn_train = time.time()\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(\n",
    "    train_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode='categorical',  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_train_samples = len(generator_top.filenames)  \n",
    "num_classes = len(generator_top.class_indices)  \n",
    "\n",
    "# load the bottleneck features saved earlier  \n",
    "train_data = np.load('../data/output_convnet/bnfeatures_train.npy')  \n",
    "\n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = generator_top.classes  \n",
    "\n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(  \n",
    "    validation_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode=None,  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "\n",
    "validation_data = np.load('../data/output_convnet/bnfeatures_val.npy')  \n",
    "\n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# top model\n",
    "model = Sequential()  \n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
    "model.add(Dense(256, activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=SGD(lr=learning_rate),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels))  \n",
    "\n",
    "model.save_weights('../data/output_convnet/bn_VGG16_model.h5')  \n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(\n",
    "    validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"acc: {:.2f}%\".format(eval_accuracy * 100))  \n",
    "print(\"loss: {}\".format(eval_loss))\n",
    "\n",
    "plt.figure(1)  \n",
    "   \n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "plt.show()\n",
    "\n",
    "tf_bn_train = time.time()    \n",
    "tt_bn_train = tf_bn_train - ti_bn_train\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# listado del train\n",
    "img_test_real = []\n",
    "img_cat_real = [] # conf mat\n",
    "img_cat_pred = [] # conf mat\n",
    "\n",
    "img_folder = sorted([folder for folder in os.listdir(test_data_dir)\n",
    "                  if os.path.isdir(os.path.join(test_data_dir, folder))])\n",
    "\n",
    "for index_folder, category in enumerate(img_folder):\n",
    "    \n",
    "    folder = os.path.join(test_data_dir, category)\n",
    "\n",
    "    for index_img, img in enumerate(os.listdir(folder)):\n",
    "        \n",
    "        if img.endswith(\".tif\"): # just in case there are other kind of files like .db\n",
    "            img_test_real.append(os.path.join(folder, img))\n",
    "            img_cat_real.append(img_folder[index_folder])\n",
    "\n",
    "    print(\"Category {0:s} has {1:d} images.\".format(category, index_img+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0 processed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 25088 and 8192 for 'Assign_131' (op: 'Assign') with input shapes: [25088,256], [8192,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 25088 and 8192 for 'Assign_131' (op: 'Assign') with input shapes: [25088,256], [8192,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-86375de6f6c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/output_convnet/bn_VGG16_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mclass_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                              ' elements.')\n\u001b[1;32m   3142\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2245\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2246\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2247\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2248\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking)\u001b[0m\n\u001b[1;32m    571\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    275\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 25088 and 8192 for 'Assign_131' (op: 'Assign') with input shapes: [25088,256], [8192,256]."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "# from keras import backend as K\n",
    "\n",
    "\n",
    "class_dictionary = np.load(\"../data/output_convnet/class_indices.npy\").item()\n",
    "num_classes = len(class_dictionary)\n",
    "\n",
    "image_path = \"test/\"\n",
    "\n",
    "\n",
    "# init time\n",
    "ti_pred = time.time()\n",
    "\n",
    "for index, img in enumerate(img_test_real):\n",
    "    \n",
    "    if not index % 100:\n",
    "        print(\"image {0:d} processed\".format(index))\n",
    "    \n",
    "    # pre process\n",
    "    img = image.load_img(img, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "#     x = x / 255\n",
    "    \n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    \n",
    "    model = VGG16(include_top=False, weights='imagenet')\n",
    "    bn_prediction = model.predict(x)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=bn_prediction.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    \n",
    "    model.load_weights(\"../data/output_convnet/bn_VGG16_model.h5\") \n",
    "\n",
    "    class_predicted = model.predict_classes(bn_prediction)\n",
    "\n",
    "    inID = class_predicted[0]  \n",
    "   \n",
    "    class_dictionary = generator_top.class_indices  \n",
    "   \n",
    "    inv_map = {v: k for k, v in class_dictionary.items()}  \n",
    "   \n",
    "    label = inv_map[inID] \n",
    "    \n",
    "    img_cat_pred.append(label)\n",
    "    \n",
    "# stop time\n",
    "tf_pred = time.time()    \n",
    "tt_pred = tf_pred - ti_pred\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
