{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = \"train\"  \n",
    "validation_data_dir = \"validation\"\n",
    "test_data_dir = \"test\"\n",
    "\n",
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "00:00:37\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ti_bn_features = time.time()\n",
    "\n",
    "model = applications.VGG19(include_top=False, weights='imagenet')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "'''\n",
    "https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L1002\n",
    "if PIL version 1.1.3 interpolation = 'lanczos'\n",
    "else interpolation = 'bicubic' \n",
    "''' \n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = None,\n",
    "    shuffle = False)\n",
    "\n",
    "nb_train_samples = len(generator.filenames)  \n",
    "num_classes = len(generator.class_indices)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n",
    "\n",
    "bnfeatures_train = model.predict_generator(\n",
    "    generator, predict_size_train)\n",
    "\n",
    "np.save('../data/output_convnet/VGG19_bnfeatures_train.npy', bnfeatures_train)\n",
    "\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "nb_validation_samples = len(generator.filenames)\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
    "   \n",
    "bnfeatures_val = model.predict_generator(  \n",
    "     generator, predict_size_validation)\n",
    "\n",
    "np.save('../data/output_convnet/VGG19_bnfeatures_val.npy', bnfeatures_val)\n",
    "\n",
    "\n",
    "tf_bn_features = time.time()    \n",
    "tt_bn_features = tf_bn_features - ti_bn_features\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 2s 507us/step - loss: 1.6768 - acc: 0.3920 - val_loss: 1.2740 - val_acc: 0.6050\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 1s 318us/step - loss: 1.2480 - acc: 0.5740 - val_loss: 1.0651 - val_acc: 0.6630\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 1s 311us/step - loss: 1.0713 - acc: 0.6323 - val_loss: 0.9085 - val_acc: 0.7580\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 1s 293us/step - loss: 0.9757 - acc: 0.6760 - val_loss: 0.8401 - val_acc: 0.7550\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 1s 289us/step - loss: 0.9082 - acc: 0.6953 - val_loss: 0.8031 - val_acc: 0.7400\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 1s 287us/step - loss: 0.8395 - acc: 0.7240 - val_loss: 0.7244 - val_acc: 0.7950\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 1s 290us/step - loss: 0.8206 - acc: 0.7290 - val_loss: 0.7102 - val_acc: 0.7810\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 1s 316us/step - loss: 0.7582 - acc: 0.7527 - val_loss: 0.6584 - val_acc: 0.8090\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 1s 291us/step - loss: 0.7383 - acc: 0.7613 - val_loss: 0.6424 - val_acc: 0.8060\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.7094 - acc: 0.7667 - val_loss: 0.6279 - val_acc: 0.7950\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.6861 - acc: 0.7793 - val_loss: 0.5942 - val_acc: 0.8190\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 1s 305us/step - loss: 0.6727 - acc: 0.7750 - val_loss: 0.5846 - val_acc: 0.8250\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.6534 - acc: 0.7857 - val_loss: 0.5762 - val_acc: 0.8120\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 1s 294us/step - loss: 0.6354 - acc: 0.7883 - val_loss: 0.5640 - val_acc: 0.8270\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.6202 - acc: 0.7983 - val_loss: 0.5539 - val_acc: 0.8260\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.6063 - acc: 0.8017 - val_loss: 0.5546 - val_acc: 0.8260\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 1s 299us/step - loss: 0.5976 - acc: 0.7970 - val_loss: 0.5355 - val_acc: 0.8230\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.5844 - acc: 0.8110 - val_loss: 0.5216 - val_acc: 0.8260\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.5766 - acc: 0.8107 - val_loss: 0.5578 - val_acc: 0.8150\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 1s 299us/step - loss: 0.5755 - acc: 0.8163 - val_loss: 0.5279 - val_acc: 0.8270\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.5670 - acc: 0.8117 - val_loss: 0.5136 - val_acc: 0.8370\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.5521 - acc: 0.8147 - val_loss: 0.5052 - val_acc: 0.8280\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.5398 - acc: 0.8187 - val_loss: 0.5042 - val_acc: 0.8330\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 1s 298us/step - loss: 0.5304 - acc: 0.8203 - val_loss: 0.4824 - val_acc: 0.8380\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.5292 - acc: 0.8237 - val_loss: 0.5184 - val_acc: 0.8230\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 1s 325us/step - loss: 0.5099 - acc: 0.8237 - val_loss: 0.4820 - val_acc: 0.8320\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 1s 299us/step - loss: 0.5083 - acc: 0.8300 - val_loss: 0.4876 - val_acc: 0.8360\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 1s 311us/step - loss: 0.5042 - acc: 0.8317 - val_loss: 0.4694 - val_acc: 0.8450\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 1s 289us/step - loss: 0.4888 - acc: 0.8390 - val_loss: 0.4816 - val_acc: 0.8290\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 1s 295us/step - loss: 0.4968 - acc: 0.8350 - val_loss: 0.4709 - val_acc: 0.8350\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 1s 297us/step - loss: 0.4863 - acc: 0.8383 - val_loss: 0.4511 - val_acc: 0.8520\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.4735 - acc: 0.8363 - val_loss: 0.4557 - val_acc: 0.8440\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 1s 312us/step - loss: 0.4900 - acc: 0.8357 - val_loss: 0.4715 - val_acc: 0.8320\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 1s 294us/step - loss: 0.4762 - acc: 0.8473 - val_loss: 0.4450 - val_acc: 0.8420\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 1s 297us/step - loss: 0.4654 - acc: 0.8497 - val_loss: 0.4507 - val_acc: 0.8380\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 1s 295us/step - loss: 0.4566 - acc: 0.8510 - val_loss: 0.4457 - val_acc: 0.8510\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 1s 314us/step - loss: 0.4546 - acc: 0.8467 - val_loss: 0.4350 - val_acc: 0.8540\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 1s 296us/step - loss: 0.4433 - acc: 0.8577 - val_loss: 0.4403 - val_acc: 0.8400\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 1s 293us/step - loss: 0.4378 - acc: 0.8510 - val_loss: 0.4538 - val_acc: 0.8430\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 1s 296us/step - loss: 0.4429 - acc: 0.8497 - val_loss: 0.4258 - val_acc: 0.8540\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 1s 306us/step - loss: 0.4285 - acc: 0.8553 - val_loss: 0.4263 - val_acc: 0.8560\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.4373 - acc: 0.8593 - val_loss: 0.4216 - val_acc: 0.8500\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 1s 307us/step - loss: 0.4303 - acc: 0.8623 - val_loss: 0.4226 - val_acc: 0.8520\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 1s 338us/step - loss: 0.4122 - acc: 0.8683 - val_loss: 0.4169 - val_acc: 0.8540\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 1s 311us/step - loss: 0.4203 - acc: 0.8610 - val_loss: 0.4322 - val_acc: 0.8540\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.4106 - acc: 0.8620 - val_loss: 0.4176 - val_acc: 0.8560\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 1s 296us/step - loss: 0.4072 - acc: 0.8697 - val_loss: 0.4334 - val_acc: 0.8450\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 1s 306us/step - loss: 0.4107 - acc: 0.8650 - val_loss: 0.4144 - val_acc: 0.8650\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 1s 300us/step - loss: 0.4103 - acc: 0.8650 - val_loss: 0.4138 - val_acc: 0.8570\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.4037 - acc: 0.8727 - val_loss: 0.4304 - val_acc: 0.8530\n",
      "1000/1000 [==============================] - 0s 94us/step\n",
      "\n",
      "\n",
      "acc: 85.30%\n",
      "loss: 0.43041255870461465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5faa0dfe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:46\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ti_bn_train = time.time()\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(\n",
    "    train_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode='categorical',  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_train_samples = len(generator_top.filenames)  \n",
    "num_classes = len(generator_top.class_indices)  \n",
    "\n",
    "\n",
    "train_data = np.load('../data/output_convnet/VGG19_bnfeatures_train.npy')\n",
    "\n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = generator_top.classes  \n",
    "\n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(  \n",
    "    validation_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode=None,  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "\n",
    "validation_data = np.load('../data/output_convnet/VGG19_bnfeatures_val.npy')  \n",
    "\n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# top model\n",
    "model = Sequential()  \n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
    "model.add(Dense(256, activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels))  \n",
    "\n",
    "model.save_weights('../data/output_convnet/bn_VGG19_model.h5')  \n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(\n",
    "    validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"acc: {:.2f}%\".format(eval_accuracy * 100))  \n",
    "print(\"loss: {}\".format(eval_loss))\n",
    "\n",
    "plt.figure(1)  \n",
    "   \n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "PATH_TO_OUTPUT = \"../data/output_convnet\"\n",
    "plt.savefig(os.path.join(PATH_TO_OUTPUT, \"bn_VGG19.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "\n",
    "plt.show()\n",
    "\n",
    "tf_bn_train = time.time()    \n",
    "tt_bn_train = tf_bn_train - ti_bn_train\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dense_1', 'dense_2', 'dropout_1', 'flatten_1']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "hdf5_file = h5py.File('../data/output_convnet/bn_VGG16_model.h5', mode='r')\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "# weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = '../data/output_convnet/bn_VGG16_model.h5'\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'train/'\n",
    "validation_data_dir = 'validation/'\n",
    "\n",
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 1000\n",
    "epochs = 50\n",
    "batch_size = 5 # con 5 funciona con 16 es imposible probar con 10\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(img_width,img_height,3))\n",
    "base_model = applications.VGG19(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dense_1', 'dense_2', 'dropout_1', 'flatten_1']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "hdf5_file = h5py.File(top_model_weights_path, mode='r')\n",
    "# print(len(hdf5_file))\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 (None, 150, 150, 3)\n",
      "1 block1_conv1 (None, 150, 150, 64)\n",
      "2 block1_conv2 (None, 150, 150, 64)\n",
      "3 block1_pool (None, 75, 75, 64)\n",
      "4 block2_conv1 (None, 75, 75, 128)\n",
      "5 block2_conv2 (None, 75, 75, 128)\n",
      "6 block2_pool (None, 37, 37, 128)\n",
      "7 block3_conv1 (None, 37, 37, 256)\n",
      "8 block3_conv2 (None, 37, 37, 256)\n",
      "9 block3_conv3 (None, 37, 37, 256)\n",
      "10 block3_conv4 (None, 37, 37, 256)\n",
      "11 block3_pool (None, 18, 18, 256)\n",
      "12 block4_conv1 (None, 18, 18, 512)\n",
      "13 block4_conv2 (None, 18, 18, 512)\n",
      "14 block4_conv3 (None, 18, 18, 512)\n",
      "15 block4_conv4 (None, 18, 18, 512)\n",
      "16 block4_pool (None, 9, 9, 512)\n",
      "17 block5_conv1 (None, 9, 9, 512)\n",
      "18 block5_conv2 (None, 9, 9, 512)\n",
      "19 block5_conv3 (None, 9, 9, 512)\n",
      "20 block5_conv4 (None, 9, 9, 512)\n",
      "21 block5_pool (None, 4, 4, 512)\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 flatten_2 (None, 8192)\n",
      "1 dense_3 (None, 256)\n",
      "2 dropout_2 (None, 256)\n",
      "3 dense_4 (None, 8)\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(top_model.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.load_weights(\"../data/output_convnet/bn_VGG19_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/envs/test/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_total = Model(input= base_model.input, output= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 (None, 150, 150, 3)\n",
      "1 block1_conv1 (None, 150, 150, 64)\n",
      "2 block1_conv2 (None, 150, 150, 64)\n",
      "3 block1_pool (None, 75, 75, 64)\n",
      "4 block2_conv1 (None, 75, 75, 128)\n",
      "5 block2_conv2 (None, 75, 75, 128)\n",
      "6 block2_pool (None, 37, 37, 128)\n",
      "7 block3_conv1 (None, 37, 37, 256)\n",
      "8 block3_conv2 (None, 37, 37, 256)\n",
      "9 block3_conv3 (None, 37, 37, 256)\n",
      "10 block3_conv4 (None, 37, 37, 256)\n",
      "11 block3_pool (None, 18, 18, 256)\n",
      "12 block4_conv1 (None, 18, 18, 512)\n",
      "13 block4_conv2 (None, 18, 18, 512)\n",
      "14 block4_conv3 (None, 18, 18, 512)\n",
      "15 block4_conv4 (None, 18, 18, 512)\n",
      "16 block4_pool (None, 9, 9, 512)\n",
      "17 block5_conv1 (None, 9, 9, 512)\n",
      "18 block5_conv2 (None, 9, 9, 512)\n",
      "19 block5_conv3 (None, 9, 9, 512)\n",
      "20 block5_conv4 (None, 9, 9, 512)\n",
      "21 block5_pool (None, 4, 4, 512)\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 flatten_2 (None, 8192)\n",
      "1 dense_3 (None, 256)\n",
      "2 dropout_2 (None, 256)\n",
      "3 dense_4 (None, 8)\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(top_model.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 (None, 150, 150, 3)\n",
      "1 block1_conv1 (None, 150, 150, 64)\n",
      "2 block1_conv2 (None, 150, 150, 64)\n",
      "3 block1_pool (None, 75, 75, 64)\n",
      "4 block2_conv1 (None, 75, 75, 128)\n",
      "5 block2_conv2 (None, 75, 75, 128)\n",
      "6 block2_pool (None, 37, 37, 128)\n",
      "7 block3_conv1 (None, 37, 37, 256)\n",
      "8 block3_conv2 (None, 37, 37, 256)\n",
      "9 block3_conv3 (None, 37, 37, 256)\n",
      "10 block3_conv4 (None, 37, 37, 256)\n",
      "11 block3_pool (None, 18, 18, 256)\n",
      "12 block4_conv1 (None, 18, 18, 512)\n",
      "13 block4_conv2 (None, 18, 18, 512)\n",
      "14 block4_conv3 (None, 18, 18, 512)\n",
      "15 block4_conv4 (None, 18, 18, 512)\n",
      "16 block4_pool (None, 9, 9, 512)\n",
      "17 block5_conv1 (None, 9, 9, 512)\n",
      "18 block5_conv2 (None, 9, 9, 512)\n",
      "19 block5_conv3 (None, 9, 9, 512)\n",
      "20 block5_conv4 (None, 9, 9, 512)\n",
      "21 block5_pool (None, 4, 4, 512)\n",
      "22 sequential_2 (None, 8)\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_total.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0, input_2 is freezed\n",
      "layer 1, block1_conv1 is trainable\n",
      "layer 2, block1_conv2 is trainable\n",
      "layer 3, block1_pool is trainable\n",
      "layer 4, block2_conv1 is trainable\n",
      "layer 5, block2_conv2 is trainable\n",
      "layer 6, block2_pool is trainable\n",
      "layer 7, block3_conv1 is trainable\n",
      "layer 8, block3_conv2 is trainable\n",
      "layer 9, block3_conv3 is trainable\n",
      "layer 10, block3_conv4 is trainable\n",
      "layer 11, block3_pool is trainable\n",
      "layer 12, block4_conv1 is trainable\n",
      "layer 13, block4_conv2 is trainable\n",
      "layer 14, block4_conv3 is trainable\n",
      "layer 15, block4_conv4 is trainable\n",
      "layer 16, block4_pool is trainable\n",
      "layer 17, block5_conv1 is trainable\n",
      "layer 18, block5_conv2 is trainable\n",
      "layer 19, block5_conv3 is trainable\n",
      "layer 20, block5_conv4 is trainable\n",
      "layer 21, block5_pool is trainable\n",
      "layer 22, sequential_2 is trainable\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_total.layers):\n",
    "    if layer.trainable:\n",
    "        print(\"layer {0:d}, {1:s} is trainable\".format(i, layer.name))\n",
    "    else:\n",
    "        print(\"layer {0:d}, {1:s} is freezed\".format(i, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model_total.layers[:15]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0, input_2 is freezed\n",
      "layer 1, block1_conv1 is freezed\n",
      "layer 2, block1_conv2 is freezed\n",
      "layer 3, block1_pool is freezed\n",
      "layer 4, block2_conv1 is freezed\n",
      "layer 5, block2_conv2 is freezed\n",
      "layer 6, block2_pool is freezed\n",
      "layer 7, block3_conv1 is freezed\n",
      "layer 8, block3_conv2 is freezed\n",
      "layer 9, block3_conv3 is freezed\n",
      "layer 10, block3_conv4 is freezed\n",
      "layer 11, block3_pool is freezed\n",
      "layer 12, block4_conv1 is freezed\n",
      "layer 13, block4_conv2 is freezed\n",
      "layer 14, block4_conv3 is freezed\n",
      "layer 15, block4_conv4 is trainable\n",
      "layer 16, block4_pool is trainable\n",
      "layer 17, block5_conv1 is trainable\n",
      "layer 18, block5_conv2 is trainable\n",
      "layer 19, block5_conv3 is trainable\n",
      "layer 20, block5_conv4 is trainable\n",
      "layer 21, block5_pool is trainable\n",
      "layer 22, sequential_2 is trainable\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_total.layers):\n",
    "    if layer.trainable:\n",
    "        print(\"layer {0:d}, {1:s} is trainable\".format(i, layer.name))\n",
    "    else:\n",
    "        print(\"layer {0:d}, {1:s} is freezed\".format(i, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total.compile(optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/envs/test/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, verbose=1, validation_data=<keras.pre..., validation_steps=1000, steps_per_epoch=600)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "600/600 [==============================] - 120s 199ms/step - loss: 0.6382 - acc: 0.7810 - val_loss: 0.3457 - val_acc: 0.8840\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 120s 199ms/step - loss: 0.4456 - acc: 0.8437 - val_loss: 0.3945 - val_acc: 0.8650\n",
      "Epoch 3/50\n",
      " 49/600 [=>............................] - ETA: 57s - loss: 0.4445 - acc: 0.8531"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# fine-tune the model\n",
    "\n",
    "# añadir medidas de acc loss como el bottleneck\n",
    "\n",
    "ti_ftuning = time.time()\n",
    "\n",
    "\n",
    "historical_data = model_total.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    verbose = 1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples)\n",
    "\n",
    "tf_ftuning = time.time()\n",
    "tt_ftuning = tf_ftuning - ti_ftuning\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_ftuning)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "PATH_TO_DF = \"../data/output_convnet\"\n",
    "\n",
    "acc = historical_data.history['acc']\n",
    "val_acc = historical_data.history['val_acc']\n",
    "loss = historical_data.history['loss']\n",
    "val_loss = historical_data.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total.save_weights('../data/output_convnet/ft_VGG19_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hdf5_file = h5py.File('../data/output_convnet/ft_VGG19_model.h5', mode='r')\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "# input_tensor = Input(shape=(img_width,img_height,3))\n",
    "model_base_pred = applications.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)  \n",
    "print(\"model base for predition loaded\")\n",
    "\n",
    "# build top model  \n",
    "model_top_pred = Sequential()  \n",
    "model_top_pred.add(Flatten(input_shape=model_base_pred.output_shape[1:]))  \n",
    "model_top_pred.add(Dense(256, activation='relu'))  \n",
    "model_top_pred.add(Dropout(0.5))  \n",
    "model_top_pred.add(Dense(8, activation='softmax'))\n",
    "print()\n",
    "print(\"model top for predition loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total_pred = Model(input= model_base_pred.input, output= model_top_pred(model_base_pred.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_total_pred.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los pesos anteriormente obtenidos en el entrenamiento\n",
    "model_total_pred.load_weights(\"../data/output_convnet/ft_VGG19_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = 'test/'\n",
    "batch_size_test = 5 # probamos con esto\n",
    "\n",
    "test_convnet = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_convnet.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle =False,\n",
    "    class_mode='categorical')\n",
    "\n",
    "cat_dict = test_generator.class_indices\n",
    "\n",
    "inverse_coding = {v: k for k, v in cat_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_data_dir = \"test/\"\n",
    "\n",
    "# listado del train\n",
    "img_test_real = [] # listado de las imagenes pareado con img_cat_real\n",
    "img_cat_real = [] # categorias de las imagenes\n",
    "\n",
    "\n",
    "img_cat_pred = [] # elementos predichos por la convnet\n",
    "\n",
    "img_folder = sorted([folder for folder in os.listdir(test_data_dir)\n",
    "                  if os.path.isdir(os.path.join(test_data_dir, folder))])\n",
    "\n",
    "for index_folder, category in enumerate(img_folder):\n",
    "    \n",
    "    folder = os.path.join(test_data_dir, category)\n",
    "\n",
    "    for index_img, img in enumerate(os.listdir(folder)):\n",
    "        \n",
    "        if img.endswith(\".tif\"): # just in case there are other kind of files like .db\n",
    "            img_test_real.append(os.path.join(folder, img))\n",
    "            img_cat_real.append(img_folder[index_folder])\n",
    "\n",
    "    print(\"Category {0:s} has {1:d} images.\".format(category, index_img+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, img_path in enumerate(img_test_real):\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "    if not index % 100:\n",
    "        print(\"image {0:d} processed\".format(index))\n",
    "        \n",
    "    # pre process\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    x = x / 255\n",
    "    \n",
    "    # prediction\n",
    "    x = model_total_pred.predict(x)\n",
    "    \n",
    "    # label\n",
    "    label = inverse_coding[np.argmax(x)]\n",
    "    \n",
    "    # store the label\n",
    "    img_cat_pred.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat_pred_arr = np.array(img_cat_pred)\n",
    "img_cat_real_arr = np.array(img_cat_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ft_conf_mat = confusion_matrix(img_cat_real_arr,img_cat_pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',size=20)\n",
    "    plt.xlabel('Predicted label',size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMG = \"../data/input_dataset\"\n",
    "class_names = sorted([folder for folder in os.listdir(PATH_TO_IMG)\n",
    "                      if os.path.isdir(os.path.join(PATH_TO_IMG, folder))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plot_confusion_matrix(ft_conf_mat, classes=class_names, title='Confusion matrix')\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plot_confusion_matrix(ft_conf_mat, classes=class_names, normalize=True, title='Confusion matrix')\n",
    "\n",
    "plt.savefig(os.path.join(PATH_TO_DF, \"ft_confmat_VGG16.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
