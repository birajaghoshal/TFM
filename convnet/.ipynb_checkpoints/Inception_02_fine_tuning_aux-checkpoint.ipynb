{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check them out\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, Flatten\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DF = \"../data/output_convnet/Inception\"\n",
    "\n",
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = \"train\"  \n",
    "validation_data_dir = \"validation\"\n",
    "test_data_dir = \"test\"\n",
    "\n",
    "n_train_samples = 3000\n",
    "n_validation_samples = 1000\n",
    "n_test_samples = 1000\n",
    "n_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://b/log.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "# saving bottleneck features\n",
    "import time\n",
    "\n",
    "ti_bn_features = time.time()\n",
    "\n",
    "model = InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "'''\n",
    "https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L1002\n",
    "if PIL version 1.1.3 interpolation = 'lanczos'\n",
    "else interpolation = 'bicubic' \n",
    "''' \n",
    "\n",
    "# train\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode = None,\n",
    "    interpolation = 'lanczos')\n",
    "\n",
    "# important step in order to get the exact number\n",
    "max_queue_size_train = int(math.ceil(n_train_samples / batch_size))\n",
    "\n",
    "bnfeatures_train = model.predict_generator(\n",
    "    generator, max_queue_size_train)\n",
    "\n",
    "np.save('../data/output_convnet/Inception/inception_bnfeatures_train_aux.npy', bnfeatures_train)\n",
    "\n",
    "# ref attribute classes --> https://keras.io/preprocessing/image/\n",
    "train_labels = generator.classes # the key attribute\n",
    "train_labels = to_categorical(train_labels, num_classes=n_classes) # the key function\n",
    "\n",
    "# validation\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode = None,\n",
    "    interpolation = 'lanczos')\n",
    "\n",
    "max_queue_size_val = int(math.ceil(n_validation_samples / batch_size))\n",
    "\n",
    "\n",
    "bnfeatures_val = model.predict_generator(  \n",
    "     generator, max_queue_size_val)\n",
    "\n",
    "np.save('../data/output_convnet/Inception/inception_bnfeatures_val_aux.npy', bnfeatures_val)\n",
    "\n",
    "val_labels = generator.classes # the key attribute\n",
    "val_labels = to_categorical(val_labels, num_classes=n_classes) # the key function\n",
    "\n",
    "\n",
    "tf_bn_features = time.time()    \n",
    "tt_bn_features = tf_bn_features - ti_bn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training top layer\n",
    "import os\n",
    "\n",
    "ti_bn_train = time.time()\n",
    "\n",
    "train_data = np.load('../data/output_convnet/Inception/inception_bnfeatures_train_aux.npy')\n",
    "val_data = np.load('../data/output_convnet/Inception/inception_bnfeatures_val_aux.npy') \n",
    "\n",
    "# top model, could be with a diff dense, optimizer, momentum -> https://keras.io/optimizers/\n",
    "model = Sequential()  \n",
    "model.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(n_classes, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "\n",
    "historical_data = model.fit(train_data, train_labels,\n",
    "                    epochs=n_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(val_data, val_labels))  \n",
    "\n",
    "# h5py\n",
    "model.save_weights('../data/output_convnet/Inception/inception_bn_model_aux.h5')  \n",
    "\n",
    "tf_bn_train = time.time()    \n",
    "tt_bn_train = tf_bn_train - ti_bn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss, acc) = model.evaluate(val_data, val_labels, batch_size=batch_size, verbose=0)\n",
    "print(\"acc: {0:.2f}% - loss: {1:f}\".format(acc * 100, loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_data.history acc and loss data over the epochs (train and validation)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc = historical_data.history['acc']\n",
    "train_loss = historical_data.history['loss']\n",
    "\n",
    "val_acc = historical_data.history['val_acc'] # validation\n",
    "val_loss = historical_data.history['val_loss'] # validation\n",
    "\n",
    "range_epochs = range(n_epochs)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.plot(range_epochs, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(range_epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.plot(range_epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(range_epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(PATH_TO_DF, \"inception_bn_acc_loss.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_weights_path = '../data/output_convnet/Inception/inception_bn_model_aux.h5'\n",
    "batch_size = 5 # con 5 funciona con 16 es imposible probar con 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "input_tensor = Input(shape=(img_width,img_height,3)) # another way to shape the input\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top model\n",
    "top_model = Sequential()\n",
    "top_model.add(GlobalMaxPooling2D(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model has its weights, now we load the weights on the top layer\n",
    "top_model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we join base and top it has to be updated to api2\n",
    "model_total = Model(input= base_model.input, output= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential is the top layer a complex one\n",
    "for i, layer in enumerate(model_total.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_total.layers):\n",
    "    if layer.trainable:\n",
    "        print(\"layer {0:d}, {1:s} is trainable\".format(i, layer.name))\n",
    "    else:\n",
    "        print(\"layer {0:d}, {1:s} is freezed\".format(i, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing layers implies they will not update their weights over the training\n",
    "# https://github.com/keras-team/keras/blob/master/keras/applications/inception_v3.py#L325\n",
    "# tha's the key to the last conv layer\n",
    "for layer in model_total.layers[:280]:\n",
    "    layer.trainable = False\n",
    "for layer in model_total.layers[280:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for updates\n",
    "for i, layer in enumerate(model_total.layers):\n",
    "    if layer.trainable:\n",
    "        print(\"layer {0:d}, {1:s} is trainable\".format(i, layer.name))\n",
    "    else:\n",
    "        print(\"layer {0:d}, {1:s} is freezed\".format(i, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel_total.compile(optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff with bottleneck, we have to use data augmentation here\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip = True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255) # not in the val data\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# fine-tune the model\n",
    "\n",
    "ti_ftuning = time.time()\n",
    "\n",
    "\n",
    "historical_data = model_total.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=n_train_samples,\n",
    "    epochs=n_epochs,\n",
    "    verbose = 1,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=n_validation_samples)\n",
    "\n",
    "tf_ftuning = time.time()\n",
    "tt_ftuning = tf_ftuning - ti_ftuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_ftuning)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total.save_weights('../data/output_convnet/Inception/inception_ft_model_aux.h5') # testing\n",
    "# model_total.save_weights('../data/output_convnet/Inception/inception_ft_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(math.ceil(n_validation_samples / batch_size))\n",
    "(loss, acc) = model_total.evaluate_generator(val_generator, steps=steps)\n",
    "print(\"acc: {0:.2f}% - loss: {1:f}\".format(acc * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = historical_data.history['acc']\n",
    "train_loss = historical_data.history['loss']\n",
    "\n",
    "val_acc = historical_data.history['val_acc'] # validation\n",
    "val_loss = historical_data.history['val_loss'] # validation\n",
    "\n",
    "print(\"train acc mean: {0:.2f} * train loss mean: {1:.2f}\".format(np.average(train_acc),np.average(train_loss)))\n",
    "print(\"validation acc mean: {0:.2f} * validation loss mean: {1:.2f}\".format(np.average(val_acc),np.average(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_data.history acc and loss data over the epochs (train and validation)\n",
    "\n",
    "range_epochs = range(n_epochs)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.plot(range_epochs, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(range_epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.plot(range_epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(range_epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(PATH_TO_DF, \"VGG19_ft_testing_acc_loss.png\"), bbox_inches='tight')\n",
    "# plt.savefig(os.path.join(PATH_TO_DF, \"VGG19_ft_acc_loss.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import h5py\n",
    "\n",
    "# # hdf5_file = h5py.File('../data/output_convnet/VGG19/VGG19_ft_model.h5', mode='r')\n",
    "\n",
    "# model_base = InceptionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)  \n",
    "\n",
    "# # top model\n",
    "# top_model = Sequential()\n",
    "# # model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "# top_model.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\n",
    "# top_model.add(Dense(1024, activation='relu'))\n",
    "# top_model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# model_total = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "# # loading the weights trained before\n",
    "# model_total.load_weights(\"../data/output_convnet/Inception/inception_ft_model.h5\")\n",
    "\n",
    "# model_total.compile(optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "#               loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convnet = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_convnet.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle =False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(math.ceil(n_test_samples / batch_size))\n",
    "\n",
    "(loss, acc) = model_total.evaluate_generator(test_generator, steps=steps)\n",
    "\n",
    "print(\"acc: {0:.2f}% - loss: {1:f}\".format(acc * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_total.predict_generator(test_generator, steps = steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "PATH_TO_IMG = \"../data/input_dataset\"\n",
    "\n",
    "prediction_list = []\n",
    "real_label_list = []\n",
    "\n",
    "cat_dict = test_generator.class_indices # the key attribute\n",
    "inverse_coding = {value: key for key, value in cat_dict.items()} # dict of categories\n",
    "\n",
    "for label in test_generator.classes:\n",
    "    real_label_list.append(inverse_coding[label])\n",
    "    \n",
    "for prediction in predictions:\n",
    "    prediction_list.append(inverse_coding[np.argmax(prediction)])\n",
    "\n",
    "# in order to get the confusion matrix\n",
    "class_names = sorted([folder for folder in os.listdir(PATH_TO_IMG)\n",
    "                  if os.path.isdir(os.path.join(PATH_TO_IMG, folder))])\n",
    "prediction_list_arr = np.array(prediction_list) \n",
    "real_label_list_arr = np.array(real_label_list)\n",
    "\n",
    "inception_cm_ft = confusion_matrix(real_label_list_arr,prediction_list_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',size=20)\n",
    "    plt.xlabel('Predicted label',size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plot_confusion_matrix(inception_cm_ft, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plot_confusion_matrix(inception_cm_ft, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.savefig(os.path.join(PATH_TO_DF, \"inception_ft_test.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
