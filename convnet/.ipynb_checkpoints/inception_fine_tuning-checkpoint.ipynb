{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = \"train\"  \n",
    "validation_data_dir = \"validation\"\n",
    "test_data_dir = \"test\"\n",
    "\n",
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "00:00:26\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ti_bn_features = time.time()\n",
    "\n",
    "model = InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "'''\n",
    "https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L1002\n",
    "if PIL version 1.1.3 interpolation = 'lanczos'\n",
    "else interpolation = 'bicubic' \n",
    "''' \n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = None,\n",
    "    shuffle = False)\n",
    "\n",
    "nb_train_samples = len(generator.filenames)  \n",
    "num_classes = len(generator.class_indices)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n",
    "\n",
    "bnfeatures_train = model.predict_generator(\n",
    "    generator, predict_size_train)\n",
    "\n",
    "np.save('../data/output_convnet/inception_bnfeatures_train.npy', bnfeatures_train)\n",
    "\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "nb_validation_samples = len(generator.filenames)\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
    "   \n",
    "bnfeatures_val = model.predict_generator(  \n",
    "     generator, predict_size_validation)\n",
    "\n",
    "np.save('../data/output_convnet/inception_bnfeatures_val.npy', bnfeatures_val)\n",
    "\n",
    "\n",
    "tf_bn_features = time.time()    \n",
    "tt_bn_features = tf_bn_features - ti_bn_features\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 2s 506us/step - loss: 1.6494 - acc: 0.4043 - val_loss: 1.3851 - val_acc: 0.5640\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 1s 314us/step - loss: 1.2265 - acc: 0.6750 - val_loss: 1.1575 - val_acc: 0.7240\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 1s 299us/step - loss: 1.0379 - acc: 0.7650 - val_loss: 1.0248 - val_acc: 0.7540\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 1s 305us/step - loss: 0.9147 - acc: 0.7940 - val_loss: 0.9295 - val_acc: 0.7720\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 1s 316us/step - loss: 0.8254 - acc: 0.8100 - val_loss: 0.8681 - val_acc: 0.7700\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 1s 308us/step - loss: 0.7592 - acc: 0.8210 - val_loss: 0.8125 - val_acc: 0.7870\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 1s 307us/step - loss: 0.7048 - acc: 0.8307 - val_loss: 0.7695 - val_acc: 0.7930\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 1s 300us/step - loss: 0.6586 - acc: 0.8427 - val_loss: 0.7413 - val_acc: 0.7960\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 1s 311us/step - loss: 0.6198 - acc: 0.8490 - val_loss: 0.7047 - val_acc: 0.8070\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 1s 314us/step - loss: 0.5877 - acc: 0.8583 - val_loss: 0.6821 - val_acc: 0.8150\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 1s 366us/step - loss: 0.5593 - acc: 0.8610 - val_loss: 0.6623 - val_acc: 0.8220\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 1s 337us/step - loss: 0.5338 - acc: 0.8707 - val_loss: 0.6480 - val_acc: 0.8170\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 1s 319us/step - loss: 0.5113 - acc: 0.8703 - val_loss: 0.6305 - val_acc: 0.8240\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 1s 308us/step - loss: 0.4914 - acc: 0.8777 - val_loss: 0.6141 - val_acc: 0.8290\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 1s 318us/step - loss: 0.4736 - acc: 0.8800 - val_loss: 0.6036 - val_acc: 0.8260\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 1s 322us/step - loss: 0.4568 - acc: 0.8830 - val_loss: 0.5943 - val_acc: 0.8300\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 1s 319us/step - loss: 0.4412 - acc: 0.8890 - val_loss: 0.5835 - val_acc: 0.8310\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 1s 319us/step - loss: 0.4269 - acc: 0.8973 - val_loss: 0.5744 - val_acc: 0.8290\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 1s 338us/step - loss: 0.4137 - acc: 0.8970 - val_loss: 0.5666 - val_acc: 0.8340\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 1s 336us/step - loss: 0.4016 - acc: 0.9043 - val_loss: 0.5579 - val_acc: 0.8380\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 1s 321us/step - loss: 0.3909 - acc: 0.9070 - val_loss: 0.5534 - val_acc: 0.8340\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 1s 324us/step - loss: 0.3796 - acc: 0.9077 - val_loss: 0.5441 - val_acc: 0.8300\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 1s 317us/step - loss: 0.3697 - acc: 0.9120 - val_loss: 0.5392 - val_acc: 0.8370\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 1s 313us/step - loss: 0.3601 - acc: 0.9147 - val_loss: 0.5321 - val_acc: 0.8390\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 1s 319us/step - loss: 0.3514 - acc: 0.9177 - val_loss: 0.5276 - val_acc: 0.8330\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 1s 307us/step - loss: 0.3426 - acc: 0.9180 - val_loss: 0.5224 - val_acc: 0.8320\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 1s 343us/step - loss: 0.3353 - acc: 0.9237 - val_loss: 0.5180 - val_acc: 0.8390\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 1s 321us/step - loss: 0.3275 - acc: 0.9223 - val_loss: 0.5137 - val_acc: 0.8400\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 1s 320us/step - loss: 0.3211 - acc: 0.9263 - val_loss: 0.5083 - val_acc: 0.8390\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 1s 322us/step - loss: 0.3134 - acc: 0.9290 - val_loss: 0.5057 - val_acc: 0.8430\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 1s 318us/step - loss: 0.3077 - acc: 0.9307 - val_loss: 0.5006 - val_acc: 0.8390\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 1s 318us/step - loss: 0.3012 - acc: 0.9310 - val_loss: 0.4984 - val_acc: 0.8370\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 1s 324us/step - loss: 0.2953 - acc: 0.9343 - val_loss: 0.4924 - val_acc: 0.8440\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 1s 323us/step - loss: 0.2898 - acc: 0.9347 - val_loss: 0.4911 - val_acc: 0.8430\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 1s 325us/step - loss: 0.2842 - acc: 0.9347 - val_loss: 0.4905 - val_acc: 0.8420\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.2785 - acc: 0.9377 - val_loss: 0.4890 - val_acc: 0.8450\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.2733 - acc: 0.9380 - val_loss: 0.4864 - val_acc: 0.8410\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 1s 305us/step - loss: 0.2692 - acc: 0.9390 - val_loss: 0.4826 - val_acc: 0.8420\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.2638 - acc: 0.9417 - val_loss: 0.4820 - val_acc: 0.8430\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 1s 304us/step - loss: 0.2595 - acc: 0.9433 - val_loss: 0.4801 - val_acc: 0.8450\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.2553 - acc: 0.9437 - val_loss: 0.4765 - val_acc: 0.8460\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 1s 300us/step - loss: 0.2510 - acc: 0.9463 - val_loss: 0.4801 - val_acc: 0.8420\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 1s 294us/step - loss: 0.2473 - acc: 0.9460 - val_loss: 0.4752 - val_acc: 0.8440\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 1s 320us/step - loss: 0.2433 - acc: 0.9467 - val_loss: 0.4734 - val_acc: 0.8440\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 1s 307us/step - loss: 0.2394 - acc: 0.9493 - val_loss: 0.4683 - val_acc: 0.8460\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 1s 306us/step - loss: 0.2356 - acc: 0.9483 - val_loss: 0.4670 - val_acc: 0.8460\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 1s 305us/step - loss: 0.2321 - acc: 0.9500 - val_loss: 0.4680 - val_acc: 0.8480\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 1s 309us/step - loss: 0.2285 - acc: 0.9507 - val_loss: 0.4674 - val_acc: 0.8480\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 1s 320us/step - loss: 0.2250 - acc: 0.9520 - val_loss: 0.4714 - val_acc: 0.8490\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 1s 318us/step - loss: 0.2220 - acc: 0.9513 - val_loss: 0.4668 - val_acc: 0.8490\n",
      "1000/1000 [==============================] - 0s 116us/step\n",
      "\n",
      "\n",
      "acc: 84.90%\n",
      "loss: 0.466770196646452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a9d766470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:48\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ti_bn_train = time.time()\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(\n",
    "    train_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode='categorical',  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_train_samples = len(generator_top.filenames)  \n",
    "num_classes = len(generator_top.class_indices)  \n",
    "\n",
    "\n",
    "train_data = np.load('../data/output_convnet/inception_bnfeatures_train.npy')\n",
    "\n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = generator_top.classes  \n",
    "\n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "generator_top = datagen_top.flow_from_directory(  \n",
    "    validation_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode=None,  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "\n",
    "validation_data = np.load('../data/output_convnet/inception_bnfeatures_val.npy')  \n",
    "\n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "# top model\n",
    "model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels))  \n",
    "\n",
    "model.save_weights('../data/output_convnet/bn_inception_model.h5')  \n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(\n",
    "    validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"acc: {:.2f}%\".format(eval_accuracy * 100))  \n",
    "print(\"loss: {}\".format(eval_loss))\n",
    "\n",
    "plt.figure(1)  \n",
    "   \n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "PATH_TO_OUTPUT = \"../data/output_convnet\"\n",
    "plt.savefig(os.path.join(PATH_TO_OUTPUT, \"bn_inception.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "\n",
    "plt.show()\n",
    "\n",
    "tf_bn_train = time.time()    \n",
    "tt_bn_train = tf_bn_train - ti_bn_train\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dense_1', 'dense_2', 'global_average_pooling2d_2']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "hdf5_file = h5py.File('../data/output_convnet/bn_inception_model.h5', mode='r')\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_weights_path = '../data/output_convnet/bn_inception_model.h5'\n",
    "\n",
    "batch_size = 5 # con 5 funciona con 16 es imposible probar con 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(img_width,img_height,3))\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 global_average_pooling2d_4 (None, 2048)\n",
      "1 dense_3 (None, 1024)\n",
      "2 dense_4 (None, 8)\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(top_model.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.load_weights(\"../data/output_convnet/bn_inception_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/envs/test/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_total = Model(input= base_model.input, output= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_total.layers[:280]:\n",
    "    layer.trainable = False\n",
    "for layer in model_total.layers[280:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0, input_2 is freezed\n",
      "layer 1, conv2d_95 is freezed\n",
      "layer 2, batch_normalization_95 is freezed\n",
      "layer 3, activation_95 is freezed\n",
      "layer 4, conv2d_96 is freezed\n",
      "layer 5, batch_normalization_96 is freezed\n",
      "layer 6, activation_96 is freezed\n",
      "layer 7, conv2d_97 is freezed\n",
      "layer 8, batch_normalization_97 is freezed\n",
      "layer 9, activation_97 is freezed\n",
      "layer 10, max_pooling2d_5 is freezed\n",
      "layer 11, conv2d_98 is freezed\n",
      "layer 12, batch_normalization_98 is freezed\n",
      "layer 13, activation_98 is freezed\n",
      "layer 14, conv2d_99 is freezed\n",
      "layer 15, batch_normalization_99 is freezed\n",
      "layer 16, activation_99 is freezed\n",
      "layer 17, max_pooling2d_6 is freezed\n",
      "layer 18, conv2d_103 is freezed\n",
      "layer 19, batch_normalization_103 is freezed\n",
      "layer 20, activation_103 is freezed\n",
      "layer 21, conv2d_101 is freezed\n",
      "layer 22, conv2d_104 is freezed\n",
      "layer 23, batch_normalization_101 is freezed\n",
      "layer 24, batch_normalization_104 is freezed\n",
      "layer 25, activation_101 is freezed\n",
      "layer 26, activation_104 is freezed\n",
      "layer 27, average_pooling2d_10 is freezed\n",
      "layer 28, conv2d_100 is freezed\n",
      "layer 29, conv2d_102 is freezed\n",
      "layer 30, conv2d_105 is freezed\n",
      "layer 31, conv2d_106 is freezed\n",
      "layer 32, batch_normalization_100 is freezed\n",
      "layer 33, batch_normalization_102 is freezed\n",
      "layer 34, batch_normalization_105 is freezed\n",
      "layer 35, batch_normalization_106 is freezed\n",
      "layer 36, activation_100 is freezed\n",
      "layer 37, activation_102 is freezed\n",
      "layer 38, activation_105 is freezed\n",
      "layer 39, activation_106 is freezed\n",
      "layer 40, mixed0 is freezed\n",
      "layer 41, conv2d_110 is freezed\n",
      "layer 42, batch_normalization_110 is freezed\n",
      "layer 43, activation_110 is freezed\n",
      "layer 44, conv2d_108 is freezed\n",
      "layer 45, conv2d_111 is freezed\n",
      "layer 46, batch_normalization_108 is freezed\n",
      "layer 47, batch_normalization_111 is freezed\n",
      "layer 48, activation_108 is freezed\n",
      "layer 49, activation_111 is freezed\n",
      "layer 50, average_pooling2d_11 is freezed\n",
      "layer 51, conv2d_107 is freezed\n",
      "layer 52, conv2d_109 is freezed\n",
      "layer 53, conv2d_112 is freezed\n",
      "layer 54, conv2d_113 is freezed\n",
      "layer 55, batch_normalization_107 is freezed\n",
      "layer 56, batch_normalization_109 is freezed\n",
      "layer 57, batch_normalization_112 is freezed\n",
      "layer 58, batch_normalization_113 is freezed\n",
      "layer 59, activation_107 is freezed\n",
      "layer 60, activation_109 is freezed\n",
      "layer 61, activation_112 is freezed\n",
      "layer 62, activation_113 is freezed\n",
      "layer 63, mixed1 is freezed\n",
      "layer 64, conv2d_117 is freezed\n",
      "layer 65, batch_normalization_117 is freezed\n",
      "layer 66, activation_117 is freezed\n",
      "layer 67, conv2d_115 is freezed\n",
      "layer 68, conv2d_118 is freezed\n",
      "layer 69, batch_normalization_115 is freezed\n",
      "layer 70, batch_normalization_118 is freezed\n",
      "layer 71, activation_115 is freezed\n",
      "layer 72, activation_118 is freezed\n",
      "layer 73, average_pooling2d_12 is freezed\n",
      "layer 74, conv2d_114 is freezed\n",
      "layer 75, conv2d_116 is freezed\n",
      "layer 76, conv2d_119 is freezed\n",
      "layer 77, conv2d_120 is freezed\n",
      "layer 78, batch_normalization_114 is freezed\n",
      "layer 79, batch_normalization_116 is freezed\n",
      "layer 80, batch_normalization_119 is freezed\n",
      "layer 81, batch_normalization_120 is freezed\n",
      "layer 82, activation_114 is freezed\n",
      "layer 83, activation_116 is freezed\n",
      "layer 84, activation_119 is freezed\n",
      "layer 85, activation_120 is freezed\n",
      "layer 86, mixed2 is freezed\n",
      "layer 87, conv2d_122 is freezed\n",
      "layer 88, batch_normalization_122 is freezed\n",
      "layer 89, activation_122 is freezed\n",
      "layer 90, conv2d_123 is freezed\n",
      "layer 91, batch_normalization_123 is freezed\n",
      "layer 92, activation_123 is freezed\n",
      "layer 93, conv2d_121 is freezed\n",
      "layer 94, conv2d_124 is freezed\n",
      "layer 95, batch_normalization_121 is freezed\n",
      "layer 96, batch_normalization_124 is freezed\n",
      "layer 97, activation_121 is freezed\n",
      "layer 98, activation_124 is freezed\n",
      "layer 99, max_pooling2d_7 is freezed\n",
      "layer 100, mixed3 is freezed\n",
      "layer 101, conv2d_129 is freezed\n",
      "layer 102, batch_normalization_129 is freezed\n",
      "layer 103, activation_129 is freezed\n",
      "layer 104, conv2d_130 is freezed\n",
      "layer 105, batch_normalization_130 is freezed\n",
      "layer 106, activation_130 is freezed\n",
      "layer 107, conv2d_126 is freezed\n",
      "layer 108, conv2d_131 is freezed\n",
      "layer 109, batch_normalization_126 is freezed\n",
      "layer 110, batch_normalization_131 is freezed\n",
      "layer 111, activation_126 is freezed\n",
      "layer 112, activation_131 is freezed\n",
      "layer 113, conv2d_127 is freezed\n",
      "layer 114, conv2d_132 is freezed\n",
      "layer 115, batch_normalization_127 is freezed\n",
      "layer 116, batch_normalization_132 is freezed\n",
      "layer 117, activation_127 is freezed\n",
      "layer 118, activation_132 is freezed\n",
      "layer 119, average_pooling2d_13 is freezed\n",
      "layer 120, conv2d_125 is freezed\n",
      "layer 121, conv2d_128 is freezed\n",
      "layer 122, conv2d_133 is freezed\n",
      "layer 123, conv2d_134 is freezed\n",
      "layer 124, batch_normalization_125 is freezed\n",
      "layer 125, batch_normalization_128 is freezed\n",
      "layer 126, batch_normalization_133 is freezed\n",
      "layer 127, batch_normalization_134 is freezed\n",
      "layer 128, activation_125 is freezed\n",
      "layer 129, activation_128 is freezed\n",
      "layer 130, activation_133 is freezed\n",
      "layer 131, activation_134 is freezed\n",
      "layer 132, mixed4 is freezed\n",
      "layer 133, conv2d_139 is freezed\n",
      "layer 134, batch_normalization_139 is freezed\n",
      "layer 135, activation_139 is freezed\n",
      "layer 136, conv2d_140 is freezed\n",
      "layer 137, batch_normalization_140 is freezed\n",
      "layer 138, activation_140 is freezed\n",
      "layer 139, conv2d_136 is freezed\n",
      "layer 140, conv2d_141 is freezed\n",
      "layer 141, batch_normalization_136 is freezed\n",
      "layer 142, batch_normalization_141 is freezed\n",
      "layer 143, activation_136 is freezed\n",
      "layer 144, activation_141 is freezed\n",
      "layer 145, conv2d_137 is freezed\n",
      "layer 146, conv2d_142 is freezed\n",
      "layer 147, batch_normalization_137 is freezed\n",
      "layer 148, batch_normalization_142 is freezed\n",
      "layer 149, activation_137 is freezed\n",
      "layer 150, activation_142 is freezed\n",
      "layer 151, average_pooling2d_14 is freezed\n",
      "layer 152, conv2d_135 is freezed\n",
      "layer 153, conv2d_138 is freezed\n",
      "layer 154, conv2d_143 is freezed\n",
      "layer 155, conv2d_144 is freezed\n",
      "layer 156, batch_normalization_135 is freezed\n",
      "layer 157, batch_normalization_138 is freezed\n",
      "layer 158, batch_normalization_143 is freezed\n",
      "layer 159, batch_normalization_144 is freezed\n",
      "layer 160, activation_135 is freezed\n",
      "layer 161, activation_138 is freezed\n",
      "layer 162, activation_143 is freezed\n",
      "layer 163, activation_144 is freezed\n",
      "layer 164, mixed5 is freezed\n",
      "layer 165, conv2d_149 is freezed\n",
      "layer 166, batch_normalization_149 is freezed\n",
      "layer 167, activation_149 is freezed\n",
      "layer 168, conv2d_150 is freezed\n",
      "layer 169, batch_normalization_150 is freezed\n",
      "layer 170, activation_150 is freezed\n",
      "layer 171, conv2d_146 is freezed\n",
      "layer 172, conv2d_151 is freezed\n",
      "layer 173, batch_normalization_146 is freezed\n",
      "layer 174, batch_normalization_151 is freezed\n",
      "layer 175, activation_146 is freezed\n",
      "layer 176, activation_151 is freezed\n",
      "layer 177, conv2d_147 is freezed\n",
      "layer 178, conv2d_152 is freezed\n",
      "layer 179, batch_normalization_147 is freezed\n",
      "layer 180, batch_normalization_152 is freezed\n",
      "layer 181, activation_147 is freezed\n",
      "layer 182, activation_152 is freezed\n",
      "layer 183, average_pooling2d_15 is freezed\n",
      "layer 184, conv2d_145 is freezed\n",
      "layer 185, conv2d_148 is freezed\n",
      "layer 186, conv2d_153 is freezed\n",
      "layer 187, conv2d_154 is freezed\n",
      "layer 188, batch_normalization_145 is freezed\n",
      "layer 189, batch_normalization_148 is freezed\n",
      "layer 190, batch_normalization_153 is freezed\n",
      "layer 191, batch_normalization_154 is freezed\n",
      "layer 192, activation_145 is freezed\n",
      "layer 193, activation_148 is freezed\n",
      "layer 194, activation_153 is freezed\n",
      "layer 195, activation_154 is freezed\n",
      "layer 196, mixed6 is freezed\n",
      "layer 197, conv2d_159 is freezed\n",
      "layer 198, batch_normalization_159 is freezed\n",
      "layer 199, activation_159 is freezed\n",
      "layer 200, conv2d_160 is freezed\n",
      "layer 201, batch_normalization_160 is freezed\n",
      "layer 202, activation_160 is freezed\n",
      "layer 203, conv2d_156 is freezed\n",
      "layer 204, conv2d_161 is freezed\n",
      "layer 205, batch_normalization_156 is freezed\n",
      "layer 206, batch_normalization_161 is freezed\n",
      "layer 207, activation_156 is freezed\n",
      "layer 208, activation_161 is freezed\n",
      "layer 209, conv2d_157 is freezed\n",
      "layer 210, conv2d_162 is freezed\n",
      "layer 211, batch_normalization_157 is freezed\n",
      "layer 212, batch_normalization_162 is freezed\n",
      "layer 213, activation_157 is freezed\n",
      "layer 214, activation_162 is freezed\n",
      "layer 215, average_pooling2d_16 is freezed\n",
      "layer 216, conv2d_155 is freezed\n",
      "layer 217, conv2d_158 is freezed\n",
      "layer 218, conv2d_163 is freezed\n",
      "layer 219, conv2d_164 is freezed\n",
      "layer 220, batch_normalization_155 is freezed\n",
      "layer 221, batch_normalization_158 is freezed\n",
      "layer 222, batch_normalization_163 is freezed\n",
      "layer 223, batch_normalization_164 is freezed\n",
      "layer 224, activation_155 is freezed\n",
      "layer 225, activation_158 is freezed\n",
      "layer 226, activation_163 is freezed\n",
      "layer 227, activation_164 is freezed\n",
      "layer 228, mixed7 is freezed\n",
      "layer 229, conv2d_167 is freezed\n",
      "layer 230, batch_normalization_167 is freezed\n",
      "layer 231, activation_167 is freezed\n",
      "layer 232, conv2d_168 is freezed\n",
      "layer 233, batch_normalization_168 is freezed\n",
      "layer 234, activation_168 is freezed\n",
      "layer 235, conv2d_165 is freezed\n",
      "layer 236, conv2d_169 is freezed\n",
      "layer 237, batch_normalization_165 is freezed\n",
      "layer 238, batch_normalization_169 is freezed\n",
      "layer 239, activation_165 is freezed\n",
      "layer 240, activation_169 is freezed\n",
      "layer 241, conv2d_166 is freezed\n",
      "layer 242, conv2d_170 is freezed\n",
      "layer 243, batch_normalization_166 is freezed\n",
      "layer 244, batch_normalization_170 is freezed\n",
      "layer 245, activation_166 is freezed\n",
      "layer 246, activation_170 is freezed\n",
      "layer 247, max_pooling2d_8 is freezed\n",
      "layer 248, mixed8 is freezed\n",
      "layer 249, conv2d_175 is freezed\n",
      "layer 250, batch_normalization_175 is freezed\n",
      "layer 251, activation_175 is freezed\n",
      "layer 252, conv2d_172 is freezed\n",
      "layer 253, conv2d_176 is freezed\n",
      "layer 254, batch_normalization_172 is freezed\n",
      "layer 255, batch_normalization_176 is freezed\n",
      "layer 256, activation_172 is freezed\n",
      "layer 257, activation_176 is freezed\n",
      "layer 258, conv2d_173 is freezed\n",
      "layer 259, conv2d_174 is freezed\n",
      "layer 260, conv2d_177 is freezed\n",
      "layer 261, conv2d_178 is freezed\n",
      "layer 262, average_pooling2d_17 is freezed\n",
      "layer 263, conv2d_171 is freezed\n",
      "layer 264, batch_normalization_173 is freezed\n",
      "layer 265, batch_normalization_174 is freezed\n",
      "layer 266, batch_normalization_177 is freezed\n",
      "layer 267, batch_normalization_178 is freezed\n",
      "layer 268, conv2d_179 is freezed\n",
      "layer 269, batch_normalization_171 is freezed\n",
      "layer 270, activation_173 is freezed\n",
      "layer 271, activation_174 is freezed\n",
      "layer 272, activation_177 is freezed\n",
      "layer 273, activation_178 is freezed\n",
      "layer 274, batch_normalization_179 is freezed\n",
      "layer 275, activation_171 is freezed\n",
      "layer 276, mixed9_0 is freezed\n",
      "layer 277, concatenate_3 is freezed\n",
      "layer 278, activation_179 is freezed\n",
      "layer 279, mixed9 is freezed\n",
      "layer 280, conv2d_184 is trainable\n",
      "layer 281, batch_normalization_184 is trainable\n",
      "layer 282, activation_184 is trainable\n",
      "layer 283, conv2d_181 is trainable\n",
      "layer 284, conv2d_185 is trainable\n",
      "layer 285, batch_normalization_181 is trainable\n",
      "layer 286, batch_normalization_185 is trainable\n",
      "layer 287, activation_181 is trainable\n",
      "layer 288, activation_185 is trainable\n",
      "layer 289, conv2d_182 is trainable\n",
      "layer 290, conv2d_183 is trainable\n",
      "layer 291, conv2d_186 is trainable\n",
      "layer 292, conv2d_187 is trainable\n",
      "layer 293, average_pooling2d_18 is trainable\n",
      "layer 294, conv2d_180 is trainable\n",
      "layer 295, batch_normalization_182 is trainable\n",
      "layer 296, batch_normalization_183 is trainable\n",
      "layer 297, batch_normalization_186 is trainable\n",
      "layer 298, batch_normalization_187 is trainable\n",
      "layer 299, conv2d_188 is trainable\n",
      "layer 300, batch_normalization_180 is trainable\n",
      "layer 301, activation_182 is trainable\n",
      "layer 302, activation_183 is trainable\n",
      "layer 303, activation_186 is trainable\n",
      "layer 304, activation_187 is trainable\n",
      "layer 305, batch_normalization_188 is trainable\n",
      "layer 306, activation_180 is trainable\n",
      "layer 307, mixed9_1 is trainable\n",
      "layer 308, concatenate_4 is trainable\n",
      "layer 309, activation_188 is trainable\n",
      "layer 310, mixed10 is trainable\n",
      "layer 311, sequential_4 is trainable\n"
     ]
    }
   ],
   "source": [
    "# for i, layer in enumerate(model_total.layers):\n",
    "#     if layer.trainable:\n",
    "#         print(\"layer {0:d}, {1:s} is trainable\".format(i, layer.name))\n",
    "#     else:\n",
    "#         print(\"layer {0:d}, {1:s} is freezed\".format(i, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# fine-tune the model\n",
    "\n",
    "# aadir medidas de acc loss como el bottleneck\n",
    "\n",
    "ti_ftuning = time.time()\n",
    "\n",
    "\n",
    "historical_data = model_total.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    verbose = 1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples)\n",
    "\n",
    "tf_ftuning = time.time()\n",
    "tt_ftuning = tf_ftuning - ti_ftuning\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_ftuning)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "PATH_TO_DF = \"../data/output_convnet\"\n",
    "\n",
    "acc = historical_data.history['acc']\n",
    "val_acc = historical_data.history['val_acc']\n",
    "loss = historical_data.history['loss']\n",
    "val_loss = historical_data.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total.save_weights('../data/output_convnet/ft_inception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hdf5_file = h5py.File('../data/output_convnet/ft_inception_model.h5', mode='r')\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "# input_tensor = Input(shape=(img_width,img_height,3))\n",
    "model_base_pred = IncetionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)  \n",
    "print(\"model base for predition loaded\")\n",
    "\n",
    "# build top model  \n",
    "top_model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dense(num_classes, activation='softmax'))\n",
    "print()\n",
    "print(\"model top for predition loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total_pred = Model(input= model_base_pred.input, output= model_top_pred(model_base_pred.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model_total_pred.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los pesos anteriormente obtenidos en el entrenamiento\n",
    "model_total_pred.load_weights(\"../data/output_convnet/ft_inception_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = 'test/'\n",
    "batch_size_test = 5 # probamos con esto\n",
    "\n",
    "test_convnet = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_convnet.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle =False,\n",
    "    class_mode='categorical')\n",
    "\n",
    "cat_dict = test_generator.class_indices\n",
    "\n",
    "inverse_coding = {v: k for k, v in cat_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_data_dir = \"test/\"\n",
    "\n",
    "# listado del train\n",
    "img_test_real = [] # listado de las imagenes pareado con img_cat_real\n",
    "img_cat_real = [] # categorias de las imagenes\n",
    "\n",
    "\n",
    "img_cat_pred = [] # elementos predichos por la convnet\n",
    "\n",
    "img_folder = sorted([folder for folder in os.listdir(test_data_dir)\n",
    "                  if os.path.isdir(os.path.join(test_data_dir, folder))])\n",
    "\n",
    "for index_folder, category in enumerate(img_folder):\n",
    "    \n",
    "    folder = os.path.join(test_data_dir, category)\n",
    "\n",
    "    for index_img, img in enumerate(os.listdir(folder)):\n",
    "        \n",
    "        if img.endswith(\".tif\"): # just in case there are other kind of files like .db\n",
    "            img_test_real.append(os.path.join(folder, img))\n",
    "            img_cat_real.append(img_folder[index_folder])\n",
    "\n",
    "    print(\"Category {0:s} has {1:d} images.\".format(category, index_img+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, img_path in enumerate(img_test_real):\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "    if not index % 100:\n",
    "        print(\"image {0:d} processed\".format(index))\n",
    "        \n",
    "    # pre process\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    x = x / 255\n",
    "    \n",
    "    # prediction\n",
    "    x = model_total_pred.predict(x)\n",
    "    \n",
    "    # label\n",
    "    label = inverse_coding[np.argmax(x)]\n",
    "    \n",
    "    # store the label\n",
    "    img_cat_pred.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat_pred_arr = np.array(img_cat_pred)\n",
    "img_cat_real_arr = np.array(img_cat_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ft_conf_mat = confusion_matrix(img_cat_real_arr,img_cat_pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',size=20)\n",
    "    plt.xlabel('Predicted label',size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMG = \"../data/input_dataset\"\n",
    "class_names = sorted([folder for folder in os.listdir(PATH_TO_IMG)\n",
    "                      if os.path.isdir(os.path.join(PATH_TO_IMG, folder))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plot_confusion_matrix(ft_conf_mat, classes=class_names, title='Confusion matrix')\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plot_confusion_matrix(ft_conf_mat, classes=class_names, normalize=True, title='Confusion matrix')\n",
    "\n",
    "plt.savefig(os.path.join(PATH_TO_DF, \"ft_confmat_VGG16.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# print(classification_report(y_test, pred_categorical))\n",
    "# print(\"The total accuracy is\", accuracy_score(y_test, pred_categorical))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
