{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoras\n",
    "\n",
    "* mejorar el codigo y adaptarlo a la api2 de keras\n",
    "* mejorar la lectura/escritura de los ficheros\n",
    "* mejora de la organizacion de los ficheros de los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_labels & img_list - completed path to file\n",
    "PATH_TO_LABELS_FILE = \"../data/output_dataset/img_labels\"\n",
    "PATH_TO_PATHS_FILE = \"../data/output_dataset/img_list\"\n",
    "\n",
    "# output convnet files path\n",
    "PATH_TO_OUTPUT = \"../data/output_convnet\"\n",
    "\n",
    "img_labels = []\n",
    "img_list = []\n",
    "\n",
    "with open(PATH_TO_LABELS_FILE,'r') as f_img_labels:\n",
    "    for line in f_img_labels:\n",
    "        img_labels.append(line[:-1]) \n",
    "\n",
    "with open(PATH_TO_PATHS_FILE,'r') as f_img_list:\n",
    "    for line in f_img_list:\n",
    "        img_list.append(\"../data/\"+line[:-1]) # para eliminar el retorno de carro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fc1 layer with activation relU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# if last command does not work properly\n",
    "keras_weights = \"keras_weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "base_model = VGG16(include_top=True)\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "# check for trainable layers\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     if layer.trainable:\n",
    "#         print(\"layer {0:s} is trainable\".format(layer.name))\n",
    "#     else:\n",
    "#         print(\"layer {0:s} is freezed\".format(layer.name))\n",
    "\n",
    "# model architecture\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sys import getsizeof\n",
    "\n",
    "deep_features = 4096\n",
    "VGG16_dfmap = np.empty((len(img_list),deep_features))\n",
    "\n",
    "# init time\n",
    "ti_dfmap_relU = time.time()\n",
    "\n",
    "for index, img_path in enumerate(img_list):\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "    if not index % 500:\n",
    "        print(\"image {0:d} processed\".format(index))\n",
    "\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "\n",
    "    # img preprocessing\n",
    "    img = image.load_img(img_path, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # model predict\n",
    "    x = model.predict(x)\n",
    "    \n",
    "    VGG16_dfmap[index,:] = np.squeeze(x, axis=0)\n",
    "\n",
    "# stop time\n",
    "tf_dfmap_relU = time.time()    \n",
    "tt_dfmap_relU = tf_dfmap_relU - ti_dfmap_relU\n",
    "print()\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_dfmap_relU)))\n",
    "print()\n",
    "print(\"Tamaño en memoria de la matriz de características profundas: {0:.2f}Mb\".format(getsizeof(VGG16_dfmap)/float(1<<20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the relU function\n",
    "VGG16_dfmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "# init time\n",
    "ti_h5file = time.time()\n",
    "\n",
    "hf = h5py.File(os.path.join(PATH_TO_OUTPUT, 'VGG16_dfmap_relU.h5'), 'w')\n",
    "hf.create_dataset('dfmap', data=VGG16_dfmap) #163.8 mb no compression at all\n",
    "# hf.create_dataset('dfmap', data=VGG16_dfmap,compression=\"gzip\", compression_opts=9) # 32.4 mb\n",
    "hf.close()\n",
    "\n",
    "# stop time\n",
    "tf_h5file = time.time()\n",
    "tt_h5file = tf_h5file - ti_h5file\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_h5file)))\n",
    "\n",
    "# import pickle\n",
    "# pickle.dump(VGG16_dfmap, open('../data/output_convnet/VGG16_dfmap_relU_pickle', 'wb'))\n",
    "\n",
    "# print(os.path.getsize(\"../data/output_convnet/VGG16_dfmap_relU_pickle\")/float(1<<20)) #156 mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file information\n",
    "import h5py\n",
    "\n",
    "hf = h5py.File(os.path.join(PATH_TO_OUTPUT, 'VGG16_dfmap_relU.h5'), 'r')\n",
    "print(hf.keys())\n",
    "n1 = hf.get('dfmap')\n",
    "print(type(n1))\n",
    "print(n1)\n",
    "\n",
    "n1 = np.array(n1)\n",
    "print(type(n1))\n",
    "print(n1.shape)\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fc1 layer with no activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/blob/master/keras/applications/vgg16.py # estructura implementada en keras\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# top layer of the VGG net\n",
    "model.add(Dense(4096, activation=None,name=\"fc1\")) # activation function set to none\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation=None,name=\"fc2\")) # activation function set to none\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"keras_weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "learning_rate = 0.01\n",
    "model.compile(optimizer=SGD(lr=learning_rate), loss='categorical_crossentropy')\n",
    "\n",
    "# check for trainable layers\n",
    "# for i, layer in enumerate(model.layers):\n",
    "#     if layer.trainable:\n",
    "#         print(\"layer {0:s} is trainable\".format(layer.name))\n",
    "#     else:\n",
    "#         print(\"layer {0:s} is freezed\".format(layer.name))\n",
    "        \n",
    "# for i, layer in enumerate(model.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_dfmap_no_relU = np.empty((len(img_list),deep_features))\n",
    "\n",
    "# init time\n",
    "ti_dfmap_no_relU = time.time()\n",
    "\n",
    "for index, img_path in enumerate(img_list):\n",
    "    \n",
    "    if not index % 500:\n",
    "        print(\"image {0:d} processed\".format(index))\n",
    "\n",
    "    model_no_relU = Model(input=model.input, output=model.get_layer('fc1').output)\n",
    "\n",
    "    # pre procesado de imagen\n",
    "    img = image.load_img(img_path, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # model predict\n",
    "    x = model_no_relU.predict(x)\n",
    "    \n",
    "    VGG16_dfmap_no_relU[index,:] = np.squeeze(x, axis=0)\n",
    "\n",
    "# stop time\n",
    "tf_dfmap_no_relU = time.time()    \n",
    "tt_dfmap_no_relU = tf_dfmap_no_relU - ti_dfmap_no_relU\n",
    "print()\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_dfmap_no_relU)))\n",
    "print()\n",
    "print(\"Tamaño en memoria de la matriz de características profundas: {0:.2f}Mb\".format(getsizeof(VGG16_dfmap_no_relU)/float(1<<20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the activation function set to none\n",
    "VGG16_dfmap_no_relU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init time\n",
    "ti_h5file_no_relU = time.time()\n",
    "\n",
    "hf = h5py.File(os.path.join(PATH_TO_OUTPUT, 'VGG16_dfmap_no_relU.h5'), 'w')\n",
    "hf.create_dataset('dfmap', data=VGG16_dfmap) #163.8 mb\n",
    "# hf.create_dataset('dfmap', data=VGG16_dfmap_no_relU,compression=\"gzip\", compression_opts=9) # 32.4 mb\n",
    "hf.close()\n",
    "\n",
    "# stop time\n",
    "tf_h5file_no_relU = time.time()\n",
    "tt_h5file_no_relU = tf_h5file_no_relU - ti_h5file_no_relU\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_h5file_no_relU)))\n",
    "\n",
    "# import pickle\n",
    "# pickle.dump(VGG16_dfmap_no_relU, open('../data/output_convnet/VGG16_dfmap_no_relU_pickle', 'wb'))\n",
    "\n",
    "# print(os.path.getsize(\"../data/output_convnet/VGG16_dfmap_no_relU_pickle\")/float(1<<20)) #156 mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(os.path.join(PATH_TO_OUTPUT, 'VGG16_dfmap_no_relU.h5'), 'r')\n",
    "print(hf.keys())\n",
    "n1 = hf.get('dfmap')\n",
    "print(type(n1))\n",
    "print(n1)\n",
    "\n",
    "n1 = np.array(n1)\n",
    "print(type(n1))\n",
    "print(n1.shape)\n",
    "\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
