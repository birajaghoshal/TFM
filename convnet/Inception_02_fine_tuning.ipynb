{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# check them out\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DF = \"../data/output_convnet/VGG16\"\n",
    "\n",
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = \"train\"  \n",
    "validation_data_dir = \"validation\"\n",
    "test_data_dir = \"test\"\n",
    "\n",
    "n_train_samples = 3000\n",
    "n_validation_samples = 1000\n",
    "n_test_samples = 1000\n",
    "n_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ti_bn_features = time.time()\n",
    "\n",
    "model = InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "'''\n",
    "https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L1002\n",
    "if PIL version 1.1.3 interpolation = 'lanczos'\n",
    "else interpolation = 'bicubic' \n",
    "''' \n",
    "\n",
    "# train\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = None,\n",
    "    shuffle = False,\n",
    "    interpolation = 'lanczos')\n",
    "\n",
    "# important step in order to get the exact number\n",
    "max_queue_size_train = int(math.ceil(n_train_samples / batch_size))\n",
    "\n",
    "bnfeatures_train = model.predict_generator(\n",
    "    generator, max_queue_size_train)\n",
    "\n",
    "np.save('../data/output_convnet/Inception/inception_bnfeatures_train.npy', bnfeatures_train)\n",
    "\n",
    "# validation\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')\n",
    "\n",
    "max_queue_size_val = int(math.ceil(n_validation_samples / batch_size))\n",
    "\n",
    "\n",
    "bnfeatures_val = model.predict_generator(  \n",
    "     generator, max_queue_size_val)\n",
    "\n",
    "np.save('../data/output_convnet/Inception/inception_bnfeatures_val.npy', bnfeatures_val)\n",
    "\n",
    "\n",
    "tf_bn_features = time.time()    \n",
    "tt_bn_features = tf_bn_features - ti_bn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:25\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 8 classes.\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 2s 810us/step - loss: 1.4343 - acc: 0.5513 - val_loss: 0.8317 - val_acc: 0.7690\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 2s 503us/step - loss: 0.8116 - acc: 0.7490 - val_loss: 0.6677 - val_acc: 0.8110\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 2s 531us/step - loss: 0.6434 - acc: 0.8010 - val_loss: 0.5998 - val_acc: 0.8100\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 2s 577us/step - loss: 0.5259 - acc: 0.8413 - val_loss: 0.5362 - val_acc: 0.8250\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 2s 510us/step - loss: 0.4401 - acc: 0.8600 - val_loss: 0.5046 - val_acc: 0.8210\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 2s 516us/step - loss: 0.3925 - acc: 0.8833 - val_loss: 0.4869 - val_acc: 0.8360\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 2s 517us/step - loss: 0.3662 - acc: 0.8857 - val_loss: 0.4716 - val_acc: 0.8450\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 2s 522us/step - loss: 0.3254 - acc: 0.9033 - val_loss: 0.4495 - val_acc: 0.8510\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 2s 530us/step - loss: 0.2911 - acc: 0.9173 - val_loss: 0.4481 - val_acc: 0.8480\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 2s 522us/step - loss: 0.2619 - acc: 0.9247 - val_loss: 0.4465 - val_acc: 0.8500\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 2s 510us/step - loss: 0.2512 - acc: 0.9273 - val_loss: 0.4346 - val_acc: 0.8570\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 2s 542us/step - loss: 0.2318 - acc: 0.9357 - val_loss: 0.4371 - val_acc: 0.8540\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 2s 522us/step - loss: 0.2179 - acc: 0.9453 - val_loss: 0.4377 - val_acc: 0.8520\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 2s 516us/step - loss: 0.1976 - acc: 0.9490 - val_loss: 0.4261 - val_acc: 0.8570\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 2s 516us/step - loss: 0.1838 - acc: 0.9550 - val_loss: 0.4177 - val_acc: 0.8580\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 2s 527us/step - loss: 0.1800 - acc: 0.9557 - val_loss: 0.4216 - val_acc: 0.8600\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 2s 523us/step - loss: 0.1695 - acc: 0.9577 - val_loss: 0.4106 - val_acc: 0.8650\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 2s 542us/step - loss: 0.1560 - acc: 0.9647 - val_loss: 0.4128 - val_acc: 0.8600\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 2s 506us/step - loss: 0.1536 - acc: 0.9603 - val_loss: 0.4100 - val_acc: 0.8660\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 2s 505us/step - loss: 0.1446 - acc: 0.9663 - val_loss: 0.4068 - val_acc: 0.8590\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 2s 506us/step - loss: 0.1355 - acc: 0.9663 - val_loss: 0.4068 - val_acc: 0.8600\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 2s 515us/step - loss: 0.1329 - acc: 0.9710 - val_loss: 0.4072 - val_acc: 0.8630\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 2s 504us/step - loss: 0.1274 - acc: 0.9733 - val_loss: 0.4102 - val_acc: 0.8660\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 2s 534us/step - loss: 0.1183 - acc: 0.9700 - val_loss: 0.4111 - val_acc: 0.8610\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 2s 506us/step - loss: 0.1129 - acc: 0.9760 - val_loss: 0.4050 - val_acc: 0.8640\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 2s 535us/step - loss: 0.1154 - acc: 0.9757 - val_loss: 0.4064 - val_acc: 0.8650\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 2s 520us/step - loss: 0.1026 - acc: 0.9807 - val_loss: 0.4097 - val_acc: 0.8600\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 2s 516us/step - loss: 0.0981 - acc: 0.9830 - val_loss: 0.4106 - val_acc: 0.8640\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 2s 526us/step - loss: 0.0991 - acc: 0.9817 - val_loss: 0.4060 - val_acc: 0.8710\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 2s 522us/step - loss: 0.0978 - acc: 0.9823 - val_loss: 0.4017 - val_acc: 0.8730\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 2s 521us/step - loss: 0.0958 - acc: 0.9803 - val_loss: 0.4039 - val_acc: 0.8680\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 2s 517us/step - loss: 0.0911 - acc: 0.9837 - val_loss: 0.4034 - val_acc: 0.8600\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 2s 545us/step - loss: 0.0876 - acc: 0.9833 - val_loss: 0.4039 - val_acc: 0.8680\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 2s 558us/step - loss: 0.0837 - acc: 0.9863 - val_loss: 0.4034 - val_acc: 0.8650\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 2s 516us/step - loss: 0.0817 - acc: 0.9860 - val_loss: 0.4054 - val_acc: 0.8640\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 2s 512us/step - loss: 0.0768 - acc: 0.9853 - val_loss: 0.4036 - val_acc: 0.8660\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 2s 547us/step - loss: 0.0790 - acc: 0.9830 - val_loss: 0.4044 - val_acc: 0.8650\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 2s 534us/step - loss: 0.0721 - acc: 0.9880 - val_loss: 0.4060 - val_acc: 0.8680\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 2s 515us/step - loss: 0.0694 - acc: 0.9880 - val_loss: 0.4111 - val_acc: 0.8700\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 2s 508us/step - loss: 0.0684 - acc: 0.9910 - val_loss: 0.4089 - val_acc: 0.8700\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 2s 540us/step - loss: 0.0674 - acc: 0.9913 - val_loss: 0.4068 - val_acc: 0.8720\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 2s 512us/step - loss: 0.0675 - acc: 0.9893 - val_loss: 0.4050 - val_acc: 0.8690\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 2s 521us/step - loss: 0.0636 - acc: 0.9883 - val_loss: 0.4063 - val_acc: 0.8640\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 2s 515us/step - loss: 0.0611 - acc: 0.9917 - val_loss: 0.4156 - val_acc: 0.8690\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 2s 550us/step - loss: 0.0560 - acc: 0.9910 - val_loss: 0.4137 - val_acc: 0.8670\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 2s 537us/step - loss: 0.0570 - acc: 0.9940 - val_loss: 0.4122 - val_acc: 0.8670\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 2s 531us/step - loss: 0.0582 - acc: 0.9913 - val_loss: 0.4100 - val_acc: 0.8670\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 2s 501us/step - loss: 0.0539 - acc: 0.9917 - val_loss: 0.4135 - val_acc: 0.8620\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 2s 503us/step - loss: 0.0548 - acc: 0.9923 - val_loss: 0.4089 - val_acc: 0.8680\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 2s 506us/step - loss: 0.0553 - acc: 0.9900 - val_loss: 0.4101 - val_acc: 0.8630\n"
     ]
    }
   ],
   "source": [
    "# training top layer\n",
    "import os\n",
    "\n",
    "ti_bn_train = time.time()\n",
    "\n",
    "# we have to get the classes names so we build again a generator\n",
    "datagen_top_layer = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "# train\n",
    "generator_top_layer = datagen_top_layer.flow_from_directory(\n",
    "    train_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode='categorical',  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "train_data = np.load('../data/output_convnet/Inception/inception_bnfeatures_train.npy')\n",
    "\n",
    "# ref attribute classes --> https://keras.io/preprocessing/image/\n",
    "train_labels = generator_top_layer.classes # the key attribute\n",
    "train_labels = to_categorical(train_labels, num_classes=n_classes) # the key function\n",
    "\n",
    "# validation\n",
    "generator_top_layer = datagen_top_layer.flow_from_directory(  \n",
    "    validation_data_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode=None,  \n",
    "    shuffle=False,\n",
    "    interpolation = 'lanczos')  \n",
    "\n",
    "val_data = np.load('../data/output_convnet/Inception/inception_bnfeatures_val.npy') \n",
    "\n",
    "val_labels = generator_top_layer.classes # the key attribute\n",
    "val_labels = to_categorical(val_labels, num_classes=n_classes) # the key function\n",
    "\n",
    "\n",
    "# top model, could be with a diff dense, optimizer, momentum -> https://keras.io/optimizers/\n",
    "model = Sequential()  \n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
    "model.add(Dense(256, activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(n_classes, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "\n",
    "historical_data = model.fit(train_data, train_labels,\n",
    "                    epochs=n_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(val_data, val_labels))  \n",
    "\n",
    "# h5py\n",
    "model.save_weights('../data/output_convnet/Inception/inception_bn_model.h5')  \n",
    "\n",
    "tf_bn_train = time.time()    \n",
    "tt_bn_train = tf_bn_train - ti_bn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:01:19\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_bn_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dense_1', 'dense_2', 'dropout_1', 'flatten_1']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "hdf5_file = h5py.File('../data/output_convnet/Inception/inception_bn_model.h5', mode='r')\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 86.30% - loss: 0.410055\n"
     ]
    }
   ],
   "source": [
    "(loss, acc) = model.evaluate(val_data, val_labels, batch_size=batch_size, verbose=0)\n",
    "print(\"acc: {0:.2f}% - loss: {1:f}\".format(acc * 100, loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad146718d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# historical_data.history acc and loss data over the epochs (train and validation)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc = historical_data.history['acc']\n",
    "train_loss = historical_data.history['loss']\n",
    "\n",
    "val_acc = historical_data.history['val_acc'] # validation\n",
    "val_loss = historical_data.history['val_loss'] # validation\n",
    "\n",
    "range_epochs = range(n_epochs)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.plot(range_epochs, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(range_epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.plot(range_epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(range_epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(PATH_TO_DF, \"inception_bn_acc_loss.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_weights_path = '../data/output_convnet/bn_inception_model.h5'\n",
    "\n",
    "batch_size = 5 # con 5 funciona con 16 es imposible probar con 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(img_width,img_height,3))\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(top_model.layers):\n",
    "    print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.load_weights(\"../data/output_convnet/bn_inception_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total = Model(input= base_model.input, output= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_total.layers[:280]:\n",
    "    layer.trainable = False\n",
    "for layer in model_total.layers[280:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model_total.layers):\n",
    "#     if layer.trainable:\n",
    "#         print(\"layer {0:d}, {1:s} is trainable\".format(i, layer.name))\n",
    "#     else:\n",
    "#         print(\"layer {0:d}, {1:s} is freezed\".format(i, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# fine-tune the model\n",
    "\n",
    "# aadir medidas de acc loss como el bottleneck\n",
    "\n",
    "ti_ftuning = time.time()\n",
    "\n",
    "\n",
    "historical_data = model_total.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    verbose = 1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples)\n",
    "\n",
    "tf_ftuning = time.time()\n",
    "tt_ftuning = tf_ftuning - ti_ftuning\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(tt_ftuning)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "PATH_TO_DF = \"../data/output_convnet\"\n",
    "\n",
    "acc = historical_data.history['acc']\n",
    "val_acc = historical_data.history['val_acc']\n",
    "loss = historical_data.history['loss']\n",
    "val_loss = historical_data.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total.save_weights('../data/output_convnet/ft_inception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hdf5_file = h5py.File('../data/output_convnet/ft_inception_model.h5', mode='r')\n",
    "print(list(hdf5_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "# input_tensor = Input(shape=(img_width,img_height,3))\n",
    "model_base_pred = InceptionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)  \n",
    "print(\"model base for predition loaded\")\n",
    "\n",
    "# build top model  \n",
    "top_model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dense(num_classes, activation='softmax'))\n",
    "print()\n",
    "print(\"model top for predition loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_total_pred = Model(input= model_base_pred.input, output= top_model(model_base_pred.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model_total_pred.layers):\n",
    "#     print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los pesos anteriormente obtenidos en el entrenamiento\n",
    "model_total_pred.load_weights(\"../data/output_convnet/ft_inception_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = 'test/'\n",
    "batch_size_test = 5 # probamos con esto\n",
    "\n",
    "test_convnet = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_convnet.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle =False,\n",
    "    class_mode='categorical')\n",
    "\n",
    "cat_dict = test_generator.class_indices\n",
    "\n",
    "inverse_coding = {v: k for k, v in cat_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_data_dir = \"test/\"\n",
    "\n",
    "# listado del train\n",
    "img_test_real = [] # listado de las imagenes pareado con img_cat_real\n",
    "img_cat_real = [] # categorias de las imagenes\n",
    "\n",
    "\n",
    "img_cat_pred = [] # elementos predichos por la convnet\n",
    "\n",
    "img_folder = sorted([folder for folder in os.listdir(test_data_dir)\n",
    "                  if os.path.isdir(os.path.join(test_data_dir, folder))])\n",
    "\n",
    "for index_folder, category in enumerate(img_folder):\n",
    "    \n",
    "    folder = os.path.join(test_data_dir, category)\n",
    "\n",
    "    for index_img, img in enumerate(os.listdir(folder)):\n",
    "        \n",
    "        if img.endswith(\".tif\"): # just in case there are other kind of files like .db\n",
    "            img_test_real.append(os.path.join(folder, img))\n",
    "            img_cat_real.append(img_folder[index_folder])\n",
    "\n",
    "    print(\"Category {0:s} has {1:d} images.\".format(category, index_img+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img_cat_pred))\n",
    "print(len(img_test_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, img_path in enumerate(img_test_real):\n",
    "    \n",
    "    \n",
    "    if not index % 100:\n",
    "        print(\"image {0:d} processed\".format(index))\n",
    "        \n",
    "    # pre process\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    x = x / 255\n",
    "    \n",
    "    # prediction\n",
    "    x = model_total_pred.predict(x)\n",
    "    \n",
    "    # label\n",
    "    label = inverse_coding[np.argmax(x)]\n",
    "    \n",
    "#     print(label)\n",
    "    \n",
    "    # store the label\n",
    "    img_cat_pred.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img_cat_pred))\n",
    "print(len(img_test_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat_pred_arr = np.array(img_cat_pred)\n",
    "img_cat_real_arr = np.array(img_cat_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img_cat_pred_arr))\n",
    "print(len(img_cat_real_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ft_conf_mat = confusion_matrix(img_cat_real_arr,img_cat_pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',size=20)\n",
    "    plt.xlabel('Predicted label',size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMG = \"../data/input_dataset\"\n",
    "class_names = sorted([folder for folder in os.listdir(PATH_TO_IMG)\n",
    "                      if os.path.isdir(os.path.join(PATH_TO_IMG, folder))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plot_confusion_matrix(ft_conf_mat, classes=class_names, title='Confusion matrix')\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plot_confusion_matrix(ft_conf_mat, classes=class_names, normalize=True, title='Confusion matrix')\n",
    "\n",
    "plt.savefig(os.path.join(PATH_TO_DF, \"ft_confmat_VGG16.png\"), bbox_inches='tight') # png 70kb vs jpg 135 kb\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# print(classification_report(y_test, pred_categorical))\n",
    "# print(\"The total accuracy is\", accuracy_score(y_test, pred_categorical))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
