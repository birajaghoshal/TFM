{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos - Cáncer de colon (CRC)\n",
    "\n",
    "* Introducción\n",
    "* Exploración del conjunto de datos\n",
    "* Conjunto de datos 1\n",
    "* Pre procesado de imágenes\n",
    "* Mejoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "El conjunto de datos consiste en un grupo de imágenes fueron liberadas bajo [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/) pudiéndose descargar en esta [página](https://zenodo.org/record/53169/export/hx).\n",
    "\n",
    "Cabe mencionar que la realización de los experimentos fue aprobada por el comité de ética de la Universidad de Heildelberg (Alemania) tal y como mencionan los autores Kather et al. en su [artículo](https://www.nature.com/articles/srep27988?WT.feed_name=subjects_translational-research) y así mismo se siguió la [Declaración de Helsinki](http://www.who.int/bulletin/archives/79%284%29373.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración del conjunto de datos\n",
    "\n",
    "### Conjunto de datos 1\n",
    "\n",
    "En este conjunto se hallan 8 categorías de tejido, listadas a continuación. En cada una de ellas hay 625 imágenes que **no se solapan entre sí**. Cada imagen tiene un tamaño de 150x150 px (píxeles), que se corresponden con 74$\\mathrm{\\mu}$m de tejido. En total son 5000 imágenes.\n",
    "\n",
    "Categorías seleccionadas por los investigadores\n",
    "1. Epitelio canceroso: Tejido epitelial, una o varias capas de celulas que constituyen revestimiento interno de organos y cavidades asi como la citada mucosa. https://es.wikipedia.org/wiki/Epitelio\n",
    "2. Estroma simple (de composición homogenea, estroma tumoroso, estroma extra-tumoral y tejido blando): Se trata de la matriz extracelular, es un medio de integracion fisiologico, en el que están embebidas las células, en este caso la composición es homogénea https://es.wikipedia.org/wiki/Estroma_(histolog%C3%ADa) y https://es.wikipedia.org/wiki/Matriz_extracelular\n",
    "3. Estroma complejo (células tumorosas y/o alguna célula inmune): Como el anterior pero en este caso, se hallan celulas tumorosas y alguna inmune\n",
    "4. Células inmunes (conglomerado de células inmunes y folículos linfoides submucosos): Foliculo linfoide es una agrupacion de celulas sin organización / estructura, que se encuentra asociado a mucosas. Foliculo linfoide → https://es.wikipedia.org/wiki/Tejido_linfoide_asociado_a_las_mucosas. En el caso de esta investigacion GALT.\n",
    "5. Material variado (mucosas, hemorrargía, necrosado): necrosado → conjunto de material muerto por patologia\n",
    "6. Glándulas mucosas normales\n",
    "7. Tejido adiposo: Tejido conjuntivo cuyas celulas acumulan lipidos en su citoplasma, cumple funciones mecánicas asi como fisiologicas. https://es.wikipedia.org/wiki/Tejido_adiposo\n",
    "8. Imagen de fondo (no se corresponde con tejido)\n",
    "\n",
    "### Conjunto de datos 2\n",
    "\n",
    "Se hallan 10 imágenes grandes, de tamaño 5000x5000 px, que provienen de distinta región con respecto a las imágenes del conjunto anterior. Según los investigadores pueden ser usadas para comprobar distintas combinaciones de descriptores de textura o clasificadores en un entorno real.\n",
    "\n",
    "Nota 1:\n",
    "\n",
    "Los autores liberaron los dos conjuntos de imágenes, si bien se realiza la implementación de redes convolucionales con el primero de ellos.\n",
    "\n",
    "Nota 2:\n",
    "\n",
    "Al provenir de tan solo 10 pacientes hay que tener en cuenta el sesgo que se comete en esta investigación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos 1\n",
    "\n",
    "A continuación, se muestra la estructura del conjunto de datos. Las imágenes están ordenadas en subcapetas, habiendo 625 en cada una de ellas. En total 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMG = \"input_dataset\"\n",
    "PATH_TO_OUTPUT = \"output_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = []\n",
    "img_labels = []\n",
    "img_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "img_folder = sorted([folder for folder in os.listdir(PATH_TO_IMG)\n",
    "                  if os.path.isdir(os.path.join(PATH_TO_IMG, folder))])\n",
    "\n",
    "print(\"Categories in the dataset: \",img_folder) # category = label = folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: La siguiente celda no conviene ejecutarla, es un comando de bash (consola linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bash command --> $tree -d img-raw/\n",
    "bash linux output\n",
    "\n",
    "img-raw/\n",
    "├── 01_TUMOR\n",
    "├── 02_STROMA\n",
    "├── 03_COMPLEX\n",
    "├── 04_LYMPHO\n",
    "├── 05_DEBRIS\n",
    "├── 06_MUCOSA\n",
    "├── 07_ADIPOSE\n",
    "└── 08_EMPTY\n",
    "\n",
    "8 directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_folder, category in enumerate(img_folder):\n",
    "    \n",
    "    folder = os.path.join(PATH_TO_IMG, category)\n",
    "\n",
    "    for index_img, img in enumerate(os.listdir(folder)):\n",
    "        \n",
    "        if img.endswith(\".tif\"): # just in case there are other kind of files like .db\n",
    "            img_list.append(os.path.join(folder, img))\n",
    "            img_labels.append(img_folder[index_folder])\n",
    "\n",
    "    print(\"Category {0:s} has {1:d} images.\".format(category, index_img+1))\n",
    "\n",
    "print()\n",
    "print(\"The dataset has: {0:d} images.\".format(len(img_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen tiene 150x150 px, por lo que tiene 22500 *características* (features).\n",
    "\n",
    "Las imágenes histológicas están en formato [TIF](https://en.wikipedia.org/wiki/TIFF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute once!\n",
    "# f_img_labels = open(os.path.join(PATH_TO_OUTPUT,'img_labels'),'w')\n",
    "# f_img_list = open(os.path.join(PATH_TO_OUTPUT,'img_list'),'w')\n",
    "\n",
    "\n",
    "# for label in img_labels:\n",
    "#     f_img_labels.write(label+\"\\n\")\n",
    "\n",
    "# for path in img_list:\n",
    "#     f_img_list.write(path+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra el formato de una imagen aleatoria del conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import re\n",
    "\n",
    "# get a random image shape from imgList and its attributes\n",
    "random_image_path = img_list[random.randint(0, len(img_list))]\n",
    "random_image = Image.open(random_image_path)\n",
    "extension, size, mode = random_image.format, random_image.size, random_image.mode\n",
    "\n",
    "print(\"Image's relative path: {0:s}\".format(random_image_path))\n",
    "print(\"Image's category: {0:s}\".format(re.split('_\\d+',random_image_path.split('/')[1])[0]))\n",
    "print()\n",
    "print(\"Image's metadata\")\n",
    "print(\"Image's extension: {0:s}. Image's size (width, height): ({1:d}, {2:d}). Image's mode: {3:s}.\".\\\n",
    "      format(extension, size[0],size[1],mode))\n",
    "print()\n",
    "print(\"The actual image: \")\n",
    "print()\n",
    "\n",
    "random_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueba que todas las imágenes del conjunto poseen el mismo formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "\n",
    "for count, img in enumerate(img_list):\n",
    "    \n",
    "    if (Image.open(img).format != 'TIFF' ) or \\\n",
    "    (Image.open(img).size[0] != 150) or \\\n",
    "    (Image.open(img).size[1] != 150) or \\\n",
    "    (Image.open(img).mode != 'RGB'): \n",
    "        print(\"Image %s has got something different: \" % img)\n",
    "        error += 1\n",
    "\n",
    "if (error == 0): print(\"Process finished with no errors.\")\n",
    "else: print(\"There is %d images in the dataset with some distinct image's parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre procesado de imágenes - repasar mejorar textos\n",
    "\n",
    "Se han creado varias estructuras, y dependiendo de cuál se use se deberá proceder de una forma u otra. En cualquier caso, además se han de tener en cuenta lo siguientes puntos:\n",
    "\n",
    "* Tamaño de la imagen: Cada arquitectura trabaja con un tamaño de imagen. En la función que toma como argumento la arquitectura de la red convolucional, se especifica este aspecto.\n",
    "\n",
    "* Canales en la imagen: Tal y como se ha comentado la extensión de las imágenes es TIFF, tiene 3 canales (mode) para los colores rojo, verde y azul, que en inglés se codifican como Red - Green - Blue (RGB) respectivamente. Por defecto en el archivo keras.json (ver jupyter testing/system) se especifica el *\"formato\": \"canales al final\"*, en inglés *\"image_data_format\": \"channels_last\"*. Por lo que, las imágenes se deberán pasar de esta forma <lote, altura, ancho, canales>, en inglés <batch, height, width, channels>.\n",
    "\n",
    "* Estructura del conjunto de datos: Con el atributo lotes del apartado anterior, se especifica el número de imágenes (lote) \n",
    "\n",
    "* Aumento del conjunto de imágenes (data augmentation): \n",
    "\n",
    "* Procedimiento - Pipeline: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing --> esto es un ejemplo porque se hara con funciones implementadas en keras\n",
    "\n",
    "def img_preprocessing(img, arch):\n",
    "    \n",
    "    # https://python-pillow.org/pillow-perf/\n",
    "    aux = Image.open(img)\n",
    "    \n",
    "    # input for VGG16 = VGG19 = resnet50 --> 224 x 224px (width x height)\n",
    "    \n",
    "    if(arch==\"inception\"):\n",
    "#         return aux.resize((width,height),resample = Image.BICUBIC)\n",
    "        return aux.resize((299,299),resample = Image.LANCZOS)\n",
    "    else:\n",
    "#         return aux.resize((224,224),resample = Image.BICUBIC)\n",
    "        return aux.resize((224,244),resample = Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos el funcionamiento de la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_before = Image.open(random_image_path)\n",
    "example_before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_after = img_preprocessing(random_image_path, \"VGG16\")\n",
    "example_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../system/functions.ipynb' # import util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time # execution time no the best accurate but the easiest sometimes does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definidas antes\n",
    "\n",
    "# PATH_TO_IMG = \"input_dataset\"\n",
    "# PATH_TO_OUTPUT = \"output_dataset\"\n",
    "\n",
    "# img_labels & img_list - completed path to file\n",
    "PATH_TO_LABELS_FILE = \"output_dataset/img_labels\"\n",
    "PATH_TO_PATHS_FILE = \"output_dataset/img_list\"\n",
    "\n",
    "# output convnet files path + feed\n",
    "PATH_TO_OUTPUT = \"output_convnet\"\n",
    "\n",
    "PATH_TO_DATA_AUGMENTATION = \"output_data_augmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = []\n",
    "img_list = []\n",
    "\n",
    "'''\n",
    "para eliminar el retorno de carro --> [:-1]\n",
    "para encontrar el path correcto hay que transformar \n",
    "la ruta puesto que este fichero y desde el que se crea tienen rutas distintas\n",
    "'''\n",
    "# input_dataset/01_TUMOR/2642_CRC-Prim-HE-07_025.tif_Row_1351_Col_601.tif\n",
    "\n",
    "with open(PATH_TO_LABELS_FILE,'r') as f_img_labels:\n",
    "    for line in f_img_labels:\n",
    "        img_labels.append(line[:-1]) \n",
    "\n",
    "with open(PATH_TO_PATHS_FILE,'r') as f_img_list:\n",
    "    for line in f_img_list:\n",
    "        img_list.append(\"../data/\"+line[:-1]) # para eliminar el retorno de carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_labels_arr = np.array(img_labels)\n",
    "img_list_arr = np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proporciones elegidas 60-20-20 // entrenamiento validacion y test\n",
    "TRAIN = 0.6\n",
    "VAL = 0.2\n",
    "\n",
    "# index selection\n",
    "index_selection = np.arange(len(img_list)) # tamaño de la lista\n",
    "\n",
    "np.random.shuffle(index_selection) # ahora en index_selection tenemos aleatorizado el vector\n",
    "\n",
    "# ahora tenemos aleatorizados los vectores de la misma manera (pareados)\n",
    "\n",
    "img_labels_arr_rand = img_labels_arr[index_selection]\n",
    "img_list_arr_rand = img_list_arr[index_selection]\n",
    "\n",
    "slice_1 = int(TRAIN*len(img_list)) # [0:2999] -> 3000 images to train\n",
    "slice_2 = int(slice_1+VAL*len(img_list))  # [3000:3999] -> 1000 images to validate, another 1k to test\n",
    "\n",
    "# print(slice_1)\n",
    "# print(slice_2)\n",
    "\n",
    "# muestras de entrenamiento\n",
    "\n",
    "labels_train = img_labels_arr_rand[:slice_1] \n",
    "img_list_train = img_list_arr_rand[:slice_1]\n",
    "\n",
    "# muestras validacion\n",
    "\n",
    "labels_val = img_labels_arr_rand[int(slice_1):slice_2] # 2999 +1 to 2999+1+1000\n",
    "img_list_val = img_list_arr_rand[int(slice_1):slice_2]\n",
    "\n",
    "# muestras test\n",
    "\n",
    "labels_test = img_labels_arr_rand[slice_2:]\n",
    "img_list_test = img_list_arr_rand[slice_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño muestra entrenamiento\n",
      "3000\n",
      "3000\n",
      "\n",
      "tamaño muestra validacion\n",
      "1000\n",
      "1000\n",
      "\n",
      "tamaño muestra test\n",
      "1000\n",
      "1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"tamaño muestra entrenamiento\")\n",
    "print(labels_train.shape[0])\n",
    "print(img_list_train.shape[0])\n",
    "print()\n",
    "print(\"tamaño muestra validacion\")\n",
    "print(labels_val.shape[0])\n",
    "print(img_list_val.shape[0])\n",
    "print()\n",
    "print(\"tamaño muestra test\")\n",
    "print(labels_test.shape[0])\n",
    "print(img_list_test.shape[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels_train)\n",
    "# print(img_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels_val)\n",
    "# print(img_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels_test)\n",
    "# print(img_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation, declaramos una funcion, le pasamos como argumento el listado de fotos de train, validation y test y guardamos esas fotos en un directorio creado a tal efecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation -->\n",
    "# image example data augmentation with keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "\n",
    "# generador de aleatoriedad revisar argumentos estos son unos pocos\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "\n",
    "# dataset_to_aug is a list, train, validation or test // type_of_dataset train val or test\n",
    "def data_augmentation(dataset_to_aug,labels_to_aug,type_of_dataset):\n",
    "    for image in dataset_to_aug:\n",
    "        img = load_img(image, target_size=(224, 224), interpolation='lanczos')\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape) # (1,224,224,3)\n",
    "        \n",
    "        #data augmentation\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                  save_to_dir=type_of_dataset, save_format='jpeg'):\n",
    "            i += 1\n",
    "            if i > 20:\n",
    "                break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "\n",
    "# salvar las fotos en estructura de directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dir = os.path.join(PATH_TO_DATA_AUGMENTATION,'train')\n",
    "# val_dir = os.path.join(PATH_TO_DATA_AUGMENTATION,'validation')\n",
    "# test_dir = os.path.join(PATH_TO_DATA_AUGMENTATION,'test')\n",
    "\n",
    "# data_augmentation(img_list_test,labels_test,'test') # function to save img transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_to_aug is a list, train, validation or test // type_of_dataset train val or test\n",
    "\n",
    "\n",
    "    img = load_img(image, target_size=(224, 224), interpolation='lanczos')\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape) # (1,224,224,3)\n",
    "\n",
    "\n",
    "# salvar las fotos en estructura de directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image example data augmentation with keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "newDataSet = ImageDataGenerator(rotation_range=40,width_shift_range=0.2,\\\n",
    "                                height_shift_range=0.2, rescale=1./255, shear_range=0.2,\\\n",
    "                                zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoras\n",
    "\n",
    "Relativas a la posible mejora de los resultados analíticos:\n",
    "\n",
    "* aumento de datos (data augmentation) con Keras\n",
    "\n",
    "Relativas a la mejora de los códigos Python:\n",
    "\n",
    "* mejora de código en general y estructuras, usando otras librerias más eficientes\n",
    "* mejora del análisis del conjunto de datos (comprobación de los formatos de las imágenes etc.)\n",
    "* control de errores en cada parte del proceso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
