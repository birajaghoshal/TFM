{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red convolucional - Inception\n",
    "\n",
    "1. Introducción Inception.\n",
    "2. Provision de imágenes a la arquitectura. Pre procesado de imágenes.\n",
    "3. Transferencia de aprendizaje: descriptores profundos\n",
    "    * Clasificación\n",
    "    * Medidas de desempeño\n",
    "4. Transferencia de aprendizaje: Fine tuning\n",
    "    * Medidas de desempeño\n",
    "5. Resumen. Discusión resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISTADO MEJORAS\n",
    "\n",
    "* numero fotos por funcion no especificando constante\n",
    "* mejorar organizacion imports\n",
    "* guardar en fichero los deepfeatures hdf5\n",
    "* incorparar diseño de la estructura de los folders e imagenes\n",
    "* preprocesamiento imagenes con tensorflow directamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introducción Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> To do --> checkpoint file explaining!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Provision de imágenes a la arquitectura. Pre procesado de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture paths\n",
    "INCEPTION_V3_PATH = \"pretrained-model/inception_v3.ckpt\"\n",
    "INCEPTION_V4_PATH = \"pretrained-model/inception_v4.ckpt\"\n",
    "\n",
    "# image dataset path\n",
    "PATH_TO_IMG = \"../img-raw\"\n",
    "\n",
    "# img data --> To do --> get automated\n",
    "WIDTH = 299\n",
    "HEIGHT = 299\n",
    "CHANNELS = 3\n",
    "\n",
    "# CONST --> To do --> get automated\n",
    "N_IMG = 5000 # number of imgs\n",
    "N_FEATURES =  2048 # number of deepfeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports --> To do --> get comments of each one of them, load them when they are going to be used?\n",
    "# import tensorflow as tf\n",
    "import os\n",
    "import scipy\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sys\n",
    "\n",
    "\n",
    "# general, prepocessing\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing\n",
    "from skimage.transform import resize #al final puede q no se use\n",
    "import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img categories --> subfolders\n",
    "# the images are tagged by the name folder --> To do --> wrap it in a function instead\n",
    "imgCategories = sorted([category for category in os.listdir(PATH_TO_IMG)\n",
    "                  if os.path.isdir(os.path.join(PATH_TO_IMG, category))])\n",
    "\n",
    "imgCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repasar punto de abajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img list + cat\n",
    "from collections import defaultdict\n",
    "\n",
    "imgPaths = defaultdict(list) #diccionario categoria - path/img.tif en test hay link a esta clase\n",
    "\n",
    "for imgCategory in imgCategories:\n",
    "    imgFolder = os.path.join(PATH_TO_IMG, imgCategory)\n",
    "    for img in os.listdir(imgFolder):\n",
    "        if img.endswith(\".tif\"): #just in case there are other kind of files\n",
    "            # due win backslash management method replace is used\n",
    "            imgPaths[imgCategory].append(os.path.join(imgFolder, img).replace(\"\\\\\",\"/\"))\n",
    "\n",
    "# sorting the img names\n",
    "for imgPath in imgPaths.values():\n",
    "    imgPath.sort()  \n",
    "\n",
    "#list(imgPaths.values()) #listado de fotos usado para el feed de la cnn\n",
    "#type(list(imgPaths.values()))\n",
    "#list(imgPaths.items()) # listado del diccionario categoria + fotos de categoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img pre procesing function, will be called later on\n",
    "def img_prepocessing(img):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "from scipy.misc import imresize\n",
    "\n",
    "def prepare_image(image, target_width = 299, target_height = 299, max_zoom = 0.2):\n",
    "    \"\"\"Zooms and crops the image randomly for data augmentation.\"\"\"\n",
    "\n",
    "    # First, let's find the largest bounding box with the target size ratio that fits within the image\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    image_ratio = width / height\n",
    "    target_image_ratio = target_width / target_height\n",
    "    crop_vertically = image_ratio < target_image_ratio\n",
    "    crop_width = width if crop_vertically else int(height * target_image_ratio)\n",
    "    crop_height = int(width / target_image_ratio) if crop_vertically else height\n",
    "        \n",
    "    # Now let's shrink this bounding box by a random factor (dividing the dimensions by a random number\n",
    "    # between 1.0 and 1.0 + `max_zoom`.\n",
    "    resize_factor = np.random.rand() * max_zoom + 1.0\n",
    "    crop_width = int(crop_width / resize_factor)\n",
    "    crop_height = int(crop_height / resize_factor)\n",
    "    \n",
    "    # Next, we can select a random location on the image for this bounding box.\n",
    "    x0 = np.random.randint(0, width - crop_width)\n",
    "    y0 = np.random.randint(0, height - crop_height)\n",
    "    x1 = x0 + crop_width\n",
    "    y1 = y0 + crop_height\n",
    "    \n",
    "    # Let's crop the image using the random bounding box we built.\n",
    "    image = image[y0:y1, x0:x1]\n",
    "\n",
    "    # Let's also flip the image horizontally with 50% probability:\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = np.fliplr(image)\n",
    "\n",
    "    # Now, let's resize the image to the target dimensions.\n",
    "    image = imresize(image, (target_width, target_height))\n",
    "    \n",
    "    # Finally, let's ensure that the colors are represented as\n",
    "    # 32-bit floats ranging from 0.0 to 1.0 (for now):\n",
    "    return image.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Transferencia de aprendizaje: descriptores profundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'latest_submission/'\n",
    "# all training images\n",
    "images_dir = 'SVM_training_set/'\n",
    "list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)]\n",
    "\n",
    "\n",
    "# setup tensorFlow graph initiation\n",
    "def create_graph():\n",
    "\twith gfile.FastGFile(os.path.join(model_dir, 'output.pb'), 'rb') as f:\n",
    "\t\tgraph_def = tf.GraphDef()\n",
    "\t\tgraph_def.ParseFromString(f.read())\n",
    "\t\t_ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "# extract all features from pool layer of InceptionV3\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tlabels = []\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\t\tlabels.append(re.split('_\\d+',image.split('/')[1])[0])\n",
    "\t\treturn features, labels\n",
    "\n",
    "\n",
    "features,labels = extract_features(list_images)\n",
    "\n",
    "pickle.dump(features, open('features', 'wb'))\n",
    "pickle.dump(labels, open('labels', 'wb'))\n",
    "\n",
    "features = pickle.load(open('features'))\n",
    "labels = pickle.load(open('labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matrix to hdf5\n",
    "#http://docs.h5py.org/en/latest/quick.html\n",
    "# https://stackoverflow.com/questions/29209293/how-to-store-an-array-in-hdf5-file-which-is-too-big-to-load-in-memory\n",
    "small data structure containing the meta-information on the array --> negligible\n",
    "a = numpy.arange(1000.0)\n",
    "a.nbytes\n",
    "8000\n",
    "a.itemsize\n",
    "8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasification - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasification - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasification - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance - random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Transferencia de aprendizaje: Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Resumen. Discusión resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptores profundos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
